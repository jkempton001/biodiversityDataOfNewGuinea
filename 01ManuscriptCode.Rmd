# Libraries
```{r}

# Open libraries

library(terra)
library(maps)
library(mapdata)
library(letsR)
library(sf)
library(dplyr)
library(ggplot2)
library(scico)
library(rnaturalearth)
library(rnaturalearthhires)
library(purrr)
library(smoothr)
library(readr)
library(tidyverse)
library(CoordinateCleaner)
library(countrycode)
library(ggrastr)
library(rgbif)
library(magrittr)
library(bit64)
library(keyring)
library(geodata)
library(spatstat)
library(spatstat.geom)
library(spatstat.explore)
library(scales)
library(colorspace)
library(patchwork)
library(cowplot)




```

## DOWNLOAD DATA


# Frogs

```{r}


get_gbif_credentials <- function(service_user = "jkempton001") {
  
  # Helper: Ensure a credential exists, else prompt to set it
  ensure_credential <- function(service_name) {
    existing <- tryCatch(
      key_get(service_name, username = service_user),
      error = function(e) NULL
    )
    
    if (is.null(existing)) {
      message(sprintf("No credential found for '%s'. Please enter it now.", service_name))
      key_set(service_name, username = service_user)
      existing <- key_get(service_name, username = service_user)
    }
    
    return(existing)
  }
  
  list(
    user     = ensure_credential("gbif_user"),
    password = ensure_credential("gbif_password"),
    email    = ensure_credential("gbif_email")
  )
}


# Load credentials securely
creds <- get_gbif_credentials()
#GBIF_USER <- creds$user
#GBIF_PWD <- creds$password
#GBIF_EMAIL <- creds$email
GBIF_USER <- "jkempton001"
GBIF_PWD <- creds$password
GBIF_EMAIL <- "j.kempton.001@gmail.com"



cat("GBIF credentials loaded securely from keychain\n")

# Define administrative regions ----
# Using GADM codes for precise geographic filtering
# Note: Island-level filtering on GBIF returns inaccurate results, 
# so we filter by administrative districts instead

regions <- list(
  papua_barat = "IDN.22_1",
  papua = "IDN.23_1",
  png = "PNG")
  

# Create standardized download function ----
download_gbif_occurrences <- function(region_codes, region_name) {
  # Build predicates for the download
  predicates <- list(
    pred("taxonKey", 952),  # Anura
    pred_in("basisOfRecord", c(
      "OBSERVATION",
      "MACHINE_OBSERVATION",
      "HUMAN_OBSERVATION",
      "MATERIAL_SAMPLE",
      "MATERIAL_CITATION",
      "PRESERVED_SPECIMEN",
      "OCCURRENCE"
    )),
    pred("hasGeospatialIssue", FALSE),  # remove records with location issues
    pred("hasCoordinate", TRUE),  # coordinates required
    pred("occurrenceStatus", "PRESENT")  # presence records only
  )
  
  # Add GADM predicates - handle both single and multiple regions
  if (length(region_codes) == 1) {
    predicates <- append(predicates, list(pred("gadm", region_codes)), after = 1)
  } else {
    # For multiple regions (like PNG mainland), add each as separate predicate
    gadm_preds <- map(region_codes, ~pred("gadm", .x))
    predicates <- append(predicates, list(pred_in("gadm", region_codes)), after = 1)
  }
  
  # Execute download
  download_key <- do.call(occ_download, c(
    predicates,
    format = "DWCA",  # Darwin Core Archive for reproducibility and citation
    user = GBIF_USER,
    pwd = GBIF_PWD,
    email = GBIF_EMAIL
  ))
  
  cat("Download initiated for", region_name, "- Key:", download_key, "\n")
  return(download_key)
}

# Execute downloads for each region ----
# Note: Each region must be downloaded separately due to rgbif limitations
# This approach ensures precise geographic filtering for each administrative unit

download_keys <- list()

cat("Initiating GBIF downloads for all regions...\n")

# New Guinea regions
download_keys$papua <- download_gbif_occurrences(regions$papua, "Papua")
download_keys$papua_barat <- download_gbif_occurrences(regions$papua_barat, "Papua Barat")
download_keys$png <- download_gbif_occurrences(regions$png, "PNG")


# Check download status ----
check_download_status <- function(download_keys) {
  cat("\nChecking download status...\n")
  for (region in names(download_keys)) {
    status <- occ_download_meta(download_keys[[region]])$status
    cat(region, ":", status, "\n")
  }
}

# Uncomment to check status
check_download_status(download_keys)
```

# Mammals

```{r}


get_gbif_credentials <- function(service_user = "jkempton001") {
  
  # Helper: Ensure a credential exists, else prompt to set it
  ensure_credential <- function(service_name) {
    existing <- tryCatch(
      key_get(service_name, username = service_user),
      error = function(e) NULL
    )
    
    if (is.null(existing)) {
      message(sprintf("No credential found for '%s'. Please enter it now.", service_name))
      key_set(service_name, username = service_user)
      existing <- key_get(service_name, username = service_user)
    }
    
    return(existing)
  }
  
  list(
    user     = ensure_credential("gbif_user"),
    password = ensure_credential("gbif_password"),
    email    = ensure_credential("gbif_email")
  )
}


# Load credentials securely
creds <- get_gbif_credentials()
#GBIF_USER <- creds$user
#GBIF_PWD <- creds$password
#GBIF_EMAIL <- creds$email
GBIF_USER <- "jkempton001"
GBIF_PWD <- creds$password
GBIF_EMAIL <- "j.kempton.001@gmail.com"

cat("GBIF credentials loaded securely from keychain\n")

# Define administrative regions ----
# Using GADM codes for precise geographic filtering
# Note: Island-level filtering on GBIF returns inaccurate results, 
# so we filter by administrative districts instead

regions <- list(
  papua_barat = "IDN.22_1",
  papua = "IDN.23_1",
  png = "PNG")
  

# Create standardized download function ----
download_gbif_occurrences <- function(region_codes, region_name) {
  # Build predicates for the download
  predicates <- list(
    pred("taxonKey", 359),  # Mammals
    pred_in("basisOfRecord", c(
      "OBSERVATION",
      "MACHINE_OBSERVATION",
      "HUMAN_OBSERVATION",
      "MATERIAL_SAMPLE",
      "MATERIAL_CITATION",
      "PRESERVED_SPECIMEN",
      "OCCURRENCE"
    )),
    pred("hasGeospatialIssue", FALSE),  # remove records with location issues
    pred("hasCoordinate", TRUE),  # coordinates required
    pred("occurrenceStatus", "PRESENT")  # presence records only
  )
  
  # Add GADM predicates - handle both single and multiple regions
  if (length(region_codes) == 1) {
    predicates <- append(predicates, list(pred("gadm", region_codes)), after = 1)
  } else {
    # For multiple regions (like PNG mainland), add each as separate predicate
    gadm_preds <- map(region_codes, ~pred("gadm", .x))
    predicates <- append(predicates, list(pred_in("gadm", region_codes)), after = 1)
  }
  
  # Execute download
  download_key <- do.call(occ_download, c(
    predicates,
    format = "DWCA",  # Darwin Core Archive for reproducibility and citation
    user = GBIF_USER,
    pwd = GBIF_PWD,
    email = GBIF_EMAIL
  ))
  
  cat("Download initiated for", region_name, "- Key:", download_key, "\n")
  return(download_key)
}

# Execute downloads for each region ----
# Note: Each region must be downloaded separately due to rgbif limitations
# This approach ensures precise geographic filtering for each administrative unit

download_keys <- list()

cat("Initiating GBIF downloads for all regions...\n")

# New Guinea regions
download_keys$papua <- download_gbif_occurrences(regions$papua, "Papua")
download_keys$papua_barat <- download_gbif_occurrences(regions$papua_barat, "Papua Barat")
download_keys$png <- download_gbif_occurrences(regions$png, "PNG")

# Check download status ----
check_download_status <- function(download_keys) {
  cat("\nChecking download status...\n")
  for (region in names(download_keys)) {
    status <- occ_download_meta(download_keys[[region]])$status
    cat(region, ":", status, "\n")
  }
}

# Uncomment to check status
check_download_status(download_keys)
```

# Birds

```{r}


get_gbif_credentials <- function(service_user = "jkempton001") {
  
  # Helper: Ensure a credential exists, else prompt to set it
  ensure_credential <- function(service_name) {
    existing <- tryCatch(
      key_get(service_name, username = service_user),
      error = function(e) NULL
    )
    
    if (is.null(existing)) {
      message(sprintf("No credential found for '%s'. Please enter it now.", service_name))
      key_set(service_name, username = service_user)
      existing <- key_get(service_name, username = service_user)
    }
    
    return(existing)
  }
  
  list(
    user     = ensure_credential("gbif_user"),
    password = ensure_credential("gbif_password"),
    email    = ensure_credential("gbif_email")
  )
}


# Load credentials securely
creds <- get_gbif_credentials()
GBIF_USER <- "jkempton001"
GBIF_PWD <- creds$password
GBIF_EMAIL <- "j.kempton.001@gmail.com"

cat("GBIF credentials loaded securely from keychain\n")

# Define administrative regions ----
# Using GADM codes for precise geographic filtering
# Note: Island-level filtering on GBIF returns inaccurate results, 
# so we filter by administrative districts instead

regions <- list(
  papua_barat = "IDN.22_1",
  papua = "IDN.23_1",
  png = "PNG")
  

# Create standardized download function ----
download_gbif_occurrences <- function(region_codes, region_name) {
  # Build predicates for the download
  predicates <- list(
    pred("taxonKey", 212),  # Birds
    pred_in("basisOfRecord", c(
      "OBSERVATION",
      "MACHINE_OBSERVATION",
      "HUMAN_OBSERVATION",
      "MATERIAL_SAMPLE",
      "MATERIAL_CITATION",
      "PRESERVED_SPECIMEN",
      "OCCURRENCE"
    )),
    pred("hasGeospatialIssue", FALSE),  # remove records with location issues
    pred("hasCoordinate", TRUE),  # coordinates required
    pred("occurrenceStatus", "PRESENT")  # presence records only
  )
  
  # Add GADM predicates - handle both single and multiple regions
  if (length(region_codes) == 1) {
    predicates <- append(predicates, list(pred("gadm", region_codes)), after = 1)
  } else {
    # For multiple regions (like PNG mainland), add each as separate predicate
    gadm_preds <- map(region_codes, ~pred("gadm", .x))
    predicates <- append(predicates, list(pred_in("gadm", region_codes)), after = 1)
  }
  
  # Execute download
  download_key <- do.call(occ_download, c(
    predicates,
    format = "DWCA",  # Darwin Core Archive for reproducibility and citation
    user = GBIF_USER,
    pwd = GBIF_PWD,
    email = GBIF_EMAIL
  ))
  
  cat("Download initiated for", region_name, "- Key:", download_key, "\n")
  return(download_key)
}

# Execute downloads for each region ----
# Note: Each region must be downloaded separately due to rgbif limitations
# This approach ensures precise geographic filtering for each administrative unit

download_keys <- list()

cat("Initiating GBIF downloads for all regions...\n")

# New Guinea regions
download_keys$papua <- download_gbif_occurrences(regions$papua, "Papua")
download_keys$papua_barat <- download_gbif_occurrences(regions$papua_barat, "Papua Barat")
download_keys$png <- download_gbif_occurrences(regions$png, "PNG")


# Check download status ----
check_download_status <- function(download_keys) {
  cat("\nChecking download status...\n")
  for (region in names(download_keys)) {
    status <- occ_download_meta(download_keys[[region]])$status
    cat(region, ":", status, "\n")
  }
}

# Uncomment to check status
check_download_status(download_keys)
```

# Squamates

```{r}


get_gbif_credentials <- function(service_user = "jkempton001") {
  
  # Helper: Ensure a credential exists, else prompt to set it
  ensure_credential <- function(service_name) {
    existing <- tryCatch(
      key_get(service_name, username = service_user),
      error = function(e) NULL
    )
    
    if (is.null(existing)) {
      message(sprintf("No credential found for '%s'. Please enter it now.", service_name))
      key_set(service_name, username = service_user)
      existing <- key_get(service_name, username = service_user)
    }
    
    return(existing)
  }
  
  list(
    user     = ensure_credential("gbif_user"),
    password = ensure_credential("gbif_password"),
    email    = ensure_credential("gbif_email")
  )
}


# Load credentials securely
creds <- get_gbif_credentials()
GBIF_USER <- "jkempton001"
GBIF_PWD <- creds$password
GBIF_EMAIL <- "j.kempton.001@gmail.com"

cat("GBIF credentials loaded securely from keychain\n")

# Define administrative regions ----
# Using GADM codes for precise geographic filtering
# Note: Island-level filtering on GBIF returns inaccurate results, 
# so we filter by administrative districts instead

regions <- list(
  papua_barat = "IDN.22_1",
  papua = "IDN.23_1",
  png = "PNG")
  

# Create standardized download function ----
download_gbif_occurrences <- function(region_codes, region_name) {
  # Build predicates for the download
  predicates <- list(
    pred("taxonKey", 11592253),  # Squamates
    pred_in("basisOfRecord", c(
      "OBSERVATION",
      "MACHINE_OBSERVATION",
      "HUMAN_OBSERVATION",
      "MATERIAL_SAMPLE",
      "MATERIAL_CITATION",
      "PRESERVED_SPECIMEN",
      "OCCURRENCE"
    )),
    pred("hasGeospatialIssue", FALSE),  # remove records with location issues
    pred("hasCoordinate", TRUE),  # coordinates required
    pred("occurrenceStatus", "PRESENT")  # presence records only
  )
  
  # Add GADM predicates - handle both single and multiple regions
  if (length(region_codes) == 1) {
    predicates <- append(predicates, list(pred("gadm", region_codes)), after = 1)
  } else {
    # For multiple regions (like PNG mainland), add each as separate predicate
    gadm_preds <- map(region_codes, ~pred("gadm", .x))
    predicates <- append(predicates, list(pred_in("gadm", region_codes)), after = 1)
  }
  
  # Execute download
  download_key <- do.call(occ_download, c(
    predicates,
    format = "DWCA",  # Darwin Core Archive for reproducibility and citation
    user = GBIF_USER,
    pwd = GBIF_PWD,
    email = GBIF_EMAIL
  ))
  
  cat("Download initiated for", region_name, "- Key:", download_key, "\n")
  return(download_key)
}

# Execute downloads for each region ----
# Note: Each region must be downloaded separately due to rgbif limitations
# This approach ensures precise geographic filtering for each administrative unit

download_keys <- list()

cat("Initiating GBIF downloads for all regions...\n")

# New Guinea regions
download_keys$papua <- download_gbif_occurrences(regions$papua, "Papua")
download_keys$papua_barat <- download_gbif_occurrences(regions$papua_barat, "Papua Barat")
download_keys$png <- download_gbif_occurrences(regions$png, "PNG")


# Check download status ----
check_download_status <- function(download_keys) {
  cat("\nChecking download status...\n")
  for (region in names(download_keys)) {
    status <- occ_download_meta(download_keys[[region]])$status
    cat(region, ":", status, "\n")
  }
}

# Uncomment to check status
check_download_status(download_keys)
```

# Vascular plants

```{r}


get_gbif_credentials <- function(service_user = "jkempton001") {
  
  # Helper: Ensure a credential exists, else prompt to set it
  ensure_credential <- function(service_name) {
    existing <- tryCatch(
      key_get(service_name, username = service_user),
      error = function(e) NULL
    )
    
    if (is.null(existing)) {
      message(sprintf("No credential found for '%s'. Please enter it now.", service_name))
      key_set(service_name, username = service_user)
      existing <- key_get(service_name, username = service_user)
    }
    
    return(existing)
  }
  
  list(
    user     = ensure_credential("gbif_user"),
    password = ensure_credential("gbif_password"),
    email    = ensure_credential("gbif_email")
  )
}


# Load credentials securely
creds <- get_gbif_credentials()
GBIF_USER <- "jkempton001"
GBIF_PWD <- creds$password
GBIF_EMAIL <- "j.kempton.001@gmail.com"

cat("GBIF credentials loaded securely from keychain\n")

# Define administrative regions ----
# Using GADM codes for precise geographic filtering
# Note: Island-level filtering on GBIF returns inaccurate results, 
# so we filter by administrative districts instead

regions <- list(
  papua_barat = "IDN.22_1",
  papua       = "IDN.23_1",
  png         = "PNG"
)


# Create standardized download function ----
download_gbif_occurrences <- function(region_codes, region_name) {
  # Build predicates for the download
  predicates <- list(
    pred("taxonKey", 7707728),  # Vascular plants
    pred_in("basisOfRecord", c(
      "OBSERVATION",
      "MACHINE_OBSERVATION",
      "HUMAN_OBSERVATION",
      "MATERIAL_SAMPLE",
      "MATERIAL_CITATION",
      "PRESERVED_SPECIMEN",
      "OCCURRENCE"
    )),
    pred("hasGeospatialIssue", FALSE),  # remove records with location issues
    pred("hasCoordinate", TRUE),  # coordinates required
    pred("occurrenceStatus", "PRESENT")  # presence records only
  )
  
  # Add GADM predicates - handle both single and multiple regions
  if (length(region_codes) == 1) {
    predicates <- append(predicates, list(pred("gadm", region_codes)), after = 1)
  } else {
    # For multiple regions (like PNG mainland), add each as separate predicate
    gadm_preds <- map(region_codes, ~pred("gadm", .x))
    predicates <- append(predicates, list(pred_in("gadm", region_codes)), after = 1)
  }
  
  # Execute download
  download_key <- do.call(occ_download, c(
    predicates,
    format = "DWCA",  # Darwin Core Archive for reproducibility and citation
    user = GBIF_USER,
    pwd = GBIF_PWD,
    email = GBIF_EMAIL
  ))
  
  cat("Download initiated for", region_name, "- Key:", download_key, "\n")
  return(download_key)
}

# Execute downloads for each region ----
# Note: Each region must be downloaded separately due to rgbif limitations
# This approach ensures precise geographic filtering for each administrative unit

download_keys <- list()

cat("Initiating GBIF downloads for all regions...\n")

# New Guinea regions
# New Guinea regions
download_keys$papua <- download_gbif_occurrences(regions$papua, "Papua")
download_keys$papua_barat <- download_gbif_occurrences(regions$papua_barat, "Papua Barat")
download_keys$png <- download_gbif_occurrences(regions$png, "PNG")

# Check download status ----
check_download_status <- function(download_keys) {
  cat("\nChecking download status...\n")
  for (region in names(download_keys)) {
    status <- occ_download_meta(download_keys[[region]])$status
    cat(region, ":", status, "\n")
  }
}

# Uncomment to check status
check_download_status(download_keys)
```


## IMPORT DATA

# Frogs

```{r}
# Import downloaded data ----
# Replace these with your actual download keys once downloads are complete
download_keys <- list(
  papua_barat = "0020372-250920141307145",
  papua = "0020368-250920141307145", 
  png = "0022860-250920141307145"
)

# Function to import and process regional data
import_and_process_region <- function(download_key, island, country) {
  # Import data
  data <- occ_download_get(download_key, overwrite = TRUE) %>%
    occ_download_import(na.strings = c("", NA))
  
  # Select relevant columns and add geographic identifiers
  processed_data <- data %>%
    select(gbifID, license, institutionCode, collectionCode, occurrenceID, 
           catalogNumber, recordNumber, recordedBy, eventDate, habitat, 
           eventRemarks, locality, decimalLatitude, decimalLongitude, 
           coordinateUncertaintyInMeters, coordinatePrecision, identifiedBy, 
           scientificName, kingdom, phylum, class, order, family, genus, 
           taxonRank, taxonomicStatus, elevation, elevationAccuracy, issue, 
           taxonKey, acceptedTaxonKey, speciesKey, species, acceptedScientificName, 
           verbatimScientificName, iucnRedListCategory, countryCode, 
           individualCount, year, basisOfRecord, datasetName, establishmentMeans, 
           references) %>%
    # COMPREHENSIVE data type standardization - convert ALL columns to expected types
    mutate(
      # Convert ALL potentially problematic columns to character first, then to proper type
      across(everything(), as.character)
    ) %>%
    # Now convert to proper types where needed
    mutate(
      # Numeric columns 
      decimalLatitude = as.numeric(decimalLatitude),
      decimalLongitude = as.numeric(decimalLongitude),
      coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters),
      coordinatePrecision = as.numeric(coordinatePrecision),
      elevation = as.numeric(elevation),
      elevationAccuracy = as.numeric(elevationAccuracy),
      individualCount = as.numeric(individualCount),
      year = as.numeric(year),
      
      # Keep ID columns as character (safer than bit64)
      gbifID = as.character(gbifID),
      taxonKey = as.character(taxonKey),
      acceptedTaxonKey = as.character(acceptedTaxonKey),
      speciesKey = as.character(speciesKey),
      
      # All other columns remain as character (including issue, license, eventDate, etc.)
    ) %>%
    add_column(ISLAND = island, COUNTRY = country)
  
  cat("Processed", island, "-", country, ":", nrow(processed_data), "records\n")
  return(processed_data)
}

# Define island and country assignments
region_metadata <- list(
  papua = list(island = "New Guinea", country = "Indonesian Papua"),
  papua_barat = list(island = "New Guinea", country = "Indonesian Papua"),
  png = list(island = "New Guinea", country = "Papua New Guinea")
)

# Import and process all regional datasets
cat("Importing and processing regional datasets...\n")

# Process each dataset individually with error handling
regional_datasets <- list()
for (region_name in names(download_keys)) {
  tryCatch({
    regional_datasets[[region_name]] <- import_and_process_region(
      download_keys[[region_name]], 
      region_metadata[[region_name]]$island,
      region_metadata[[region_name]]$country
    )
  }, error = function(e) {
    cat("Error processing", region_name, ":", e$message, "\n")
    regional_datasets[[region_name]] <<- NULL
  })
}

# Remove any NULL entries (failed downloads)
regional_datasets <- regional_datasets[!sapply(regional_datasets, is.null)]

cat("Successfully processed", length(regional_datasets), "regional datasets\n")

# Combine all regional datasets
cat("Combining datasets from all regions...\n")

# Additional safety check - examine data types before combining
cat("Checking data types for consistency...\n")
for (i in seq_along(regional_datasets)) {
  region_name <- names(regional_datasets)[i]
  cat("Dataset", i, "(", region_name, "):\n")
  
  # Check for problematic columns that have caused issues
  problematic_cols <- c("issue", "license", "eventDate")
  for (col in problematic_cols) {
    if (col %in% names(regional_datasets[[i]])) {
      col_type <- class(regional_datasets[[i]][[col]])[1]
      cat("  ", col, ":", col_type, "\n")
    }
  }
}

# Combine datasets (should work smoothly now with standardized types)
gbifSEAsiaFrogsOccData <- bind_rows(regional_datasets)

cat("Successfully combined", nrow(gbifSEAsiaFrogsOccData), "records from", length(regional_datasets), "regions\n")

# Optional: Check for any remaining data type issues
cat("Data summary by column type:\n")
gbifSEAsiaFrogsOccData %>% 
  summarise(across(everything(), ~class(.)[1])) %>% 
  pivot_longer(everything(), names_to = "column", values_to = "type") %>%
  count(type) %>%
  print()

# Clean and standardize GBIF data ----
gbifSEAsiaFrogsOccDataCleaned <- gbifSEAsiaFrogsOccData %>%
  # Parse accepted scientific name into components
  # Note: Many records will only have genus, or genus + species, without authority
  # This generates expected warnings for records missing some components
  separate(acceptedScientificName, 
           into = c("gen", "sp", "authority"), 
           sep = " ", 
           extra = "merge",
           fill = "right") %>%  # Fill missing pieces with NA (suppresses warnings)
  # Standardize column names to match internal dataset
  rename(collector = recordedBy,
         number = recordNumber,
         lat = decimalLatitude,
         long = decimalLongitude) %>%
  # Select core columns for modeling PLUS geographic metadata for analyses
  select(family, gen, sp, authority, collector, number, lat, long, 
         countryCode, year, coordinateUncertaintyInMeters, coordinatePrecision,
         taxonRank, ISLAND, COUNTRY)

# Quick data quality check
cat("GBIF data summary after cleaning:\n")
cat("Total records:", nrow(gbifSEAsiaFrogsOccDataCleaned), "\n")
cat("Records with genus:", sum(!is.na(gbifSEAsiaFrogsOccDataCleaned$gen)), "\n")
cat("Records with species:", sum(!is.na(gbifSEAsiaFrogsOccDataCleaned$sp)), "\n") 
cat("Records with authority:", sum(!is.na(gbifSEAsiaFrogsOccDataCleaned$authority)), "\n")
cat("Records with coordinates:", sum(!is.na(gbifSEAsiaFrogsOccDataCleaned$lat) & !is.na(gbifSEAsiaFrogsOccDataCleaned$long)), "\n")


# Summary statistics ----
cat("Dataset summary:\n")
cat("Total GBIF records:", nrow(gbifSEAsiaFrogsOccDataCleaned), "\n")
cat("Unique species:", gbifSEAsiaFrogsOccDataCleaned %>% 
      filter(!is.na(gen), !is.na(sp)) %>% 
      distinct(gen, sp) %>% 
      nrow(), "\n")

# Geographic distribution summary
cat("\nGeographic distribution:\n")
gbifSEAsiaFrogsOccDataCleaned %>% 
  filter(!is.na(ISLAND)) %>% 
  count(ISLAND, COUNTRY, sort = TRUE) %>%
  print()

# Preview the data structure for rWCVP workflow
cat("\nData structure preview for rWCVP name resolution:\n")
gbifSEAsiaFrogsOccDataCleaned %>% 
  filter(!is.na(gen), !is.na(sp)) %>%
  select(family, gen, sp, authority, ISLAND, COUNTRY) %>%
  slice_head(n = 5) %>%
  print()

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/standardised_occ_data/", "frogsOccDataStandardised_", date_stamp, ".csv")

write_csv(gbifSEAsiaFrogsOccDataCleaned, output_filename)
cat("Dataset saved as:", output_filename, "\n")
```

# Mammals

```{r}
# Import downloaded data ----
# Replace these with your actual download keys once downloads are complete
download_keys <- list(
  papua_barat = "0073761-251120083545085",
  papua = "0073760-251120083545085", 
  png = "0073762-251120083545085"
)

# Function to import and process regional data
import_and_process_region <- function(download_key, island, country) {
  # Import data
  data <- occ_download_get(download_key, overwrite = TRUE) %>%
    occ_download_import(na.strings = c("", NA))
  
  # Select relevant columns and add geographic identifiers
  processed_data <- data %>%
    select(gbifID, license, institutionCode, collectionCode, occurrenceID, 
           catalogNumber, recordNumber, recordedBy, eventDate, habitat, 
           eventRemarks, locality, decimalLatitude, decimalLongitude, 
           coordinateUncertaintyInMeters, coordinatePrecision, identifiedBy, 
           scientificName, kingdom, phylum, class, order, family, genus, 
           taxonRank, taxonomicStatus, elevation, elevationAccuracy, issue, 
           taxonKey, acceptedTaxonKey, speciesKey, species, acceptedScientificName, 
           verbatimScientificName, iucnRedListCategory, countryCode, 
           individualCount, year, basisOfRecord, datasetName, establishmentMeans, 
           references) %>%
    # COMPREHENSIVE data type standardization - convert ALL columns to expected types
    mutate(
      # Convert ALL potentially problematic columns to character first, then to proper type
      across(everything(), as.character)
    ) %>%
    # Now convert to proper types where needed
    mutate(
      # Numeric columns 
      decimalLatitude = as.numeric(decimalLatitude),
      decimalLongitude = as.numeric(decimalLongitude),
      coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters),
      coordinatePrecision = as.numeric(coordinatePrecision),
      elevation = as.numeric(elevation),
      elevationAccuracy = as.numeric(elevationAccuracy),
      individualCount = as.numeric(individualCount),
      year = as.numeric(year),
      
      # Keep ID columns as character (safer than bit64)
      gbifID = as.character(gbifID),
      taxonKey = as.character(taxonKey),
      acceptedTaxonKey = as.character(acceptedTaxonKey),
      speciesKey = as.character(speciesKey),
      
      # All other columns remain as character (including issue, license, eventDate, etc.)
    ) %>%
    add_column(ISLAND = island, COUNTRY = country)
  
  cat("Processed", island, "-", country, ":", nrow(processed_data), "records\n")
  return(processed_data)
}

# Define island and country assignments
region_metadata <- list(
  papua = list(island = "New Guinea", country = "Indonesian Papua"),
  papua_barat = list(island = "New Guinea", country = "Indonesian Papua"),
  kalimantan = list(island = "Borneo", country = "Indonesian Borneo"),
  brunei = list(island = "Borneo", country = "Brunei"),
  phillipines = list(island = "Phillipines", country = "Phillipines"),
  sabah = list(island = "Borneo", country = "Malaysian Borneo"),
  sarawak = list(island = "Borneo", country = "Malaysian Borneo"),
  java = list(island = "Java", country = "Java"),
  sumatra = list(island = "Sumatra", country = "Sumatra"),
  bali = list(island = "Bali", country = "Bali"),
  maluku = list(island = "Maluku", country = "Maluku"),
  sulawesi = list(island = "Sulawesi", country = "Sulawesi"),
  lesser_sunda_islands = list(island = "Lesser Sunda Islands", country = "Lesser Sunda Islands"),
  png = list(island = "New Guinea", country = "Papua New Guinea")
)

# Import and process all regional datasets
cat("Importing and processing regional datasets...\n")

# Process each dataset individually with error handling
regional_datasets <- list()
for (region_name in names(download_keys)) {
  tryCatch({
    regional_datasets[[region_name]] <- import_and_process_region(
      download_keys[[region_name]], 
      region_metadata[[region_name]]$island,
      region_metadata[[region_name]]$country
    )
  }, error = function(e) {
    cat("Error processing", region_name, ":", e$message, "\n")
    regional_datasets[[region_name]] <<- NULL
  })
}

# Remove any NULL entries (failed downloads)
regional_datasets <- regional_datasets[!sapply(regional_datasets, is.null)]

cat("Successfully processed", length(regional_datasets), "regional datasets\n")

# Combine all regional datasets
cat("Combining datasets from all regions...\n")

# Additional safety check - examine data types before combining
cat("Checking data types for consistency...\n")
for (i in seq_along(regional_datasets)) {
  region_name <- names(regional_datasets)[i]
  cat("Dataset", i, "(", region_name, "):\n")
  
  # Check for problematic columns that have caused issues
  problematic_cols <- c("issue", "license", "eventDate")
  for (col in problematic_cols) {
    if (col %in% names(regional_datasets[[i]])) {
      col_type <- class(regional_datasets[[i]][[col]])[1]
      cat("  ", col, ":", col_type, "\n")
    }
  }
}

# Combine datasets (should work smoothly now with standardized types)
gbifSEAsiaMammalOccData <- bind_rows(regional_datasets)

cat("Successfully combined", nrow(gbifSEAsiaMammalOccData), "records from", length(regional_datasets), "regions\n")

# Optional: Check for any remaining data type issues
cat("Data summary by column type:\n")
gbifSEAsiaMammalOccData %>% 
  summarise(across(everything(), ~class(.)[1])) %>% 
  pivot_longer(everything(), names_to = "column", values_to = "type") %>%
  count(type) %>%
  print()

# Clean and standardize GBIF data ----
gbifSEAsiaMammalOccDataCleaned <- gbifSEAsiaMammalOccData %>%
  # Parse accepted scientific name into components
  # Note: Many records will only have genus, or genus + species, without authority
  # This generates expected warnings for records missing some components
  separate(acceptedScientificName, 
           into = c("gen", "sp", "authority"), 
           sep = " ", 
           extra = "merge",
           fill = "right") %>%  # Fill missing pieces with NA (suppresses warnings)
  # Standardize column names to match internal dataset
  rename(collector = recordedBy,
         number = recordNumber,
         lat = decimalLatitude,
         long = decimalLongitude) %>%
  # Select core columns for modeling PLUS geographic metadata for analyses
  select(family, gen, sp, authority, collector, number, lat, long, 
         countryCode, year, coordinateUncertaintyInMeters, coordinatePrecision,
         taxonRank, ISLAND, COUNTRY)

# Quick data quality check
cat("GBIF data summary after cleaning:\n")
cat("Total records:", nrow(gbifSEAsiaMammalOccDataCleaned), "\n")
cat("Records with genus:", sum(!is.na(gbifSEAsiaMammalOccDataCleaned$gen)), "\n")
cat("Records with species:", sum(!is.na(gbifSEAsiaMammalOccDataCleaned$sp)), "\n") 
cat("Records with authority:", sum(!is.na(gbifSEAsiaMammalOccDataCleaned$authority)), "\n")
cat("Records with coordinates:", sum(!is.na(gbifSEAsiaMammalOccDataCleaned$lat) & !is.na(gbifSEAsiaMammalOccDataCleaned$long)), "\n")


# Summary statistics ----
cat("Dataset summary:\n")
cat("Total GBIF records:", nrow(gbifSEAsiaMammalOccDataCleaned), "\n")
cat("Unique species:", gbifSEAsiaMammalOccDataCleaned %>% 
      filter(!is.na(gen), !is.na(sp)) %>% 
      distinct(gen, sp) %>% 
      nrow(), "\n")

# Geographic distribution summary
cat("\nGeographic distribution:\n")
gbifSEAsiaMammalOccDataCleaned %>% 
  filter(!is.na(ISLAND)) %>% 
  count(ISLAND, COUNTRY, sort = TRUE) %>%
  print()

# Preview the data structure for rWCVP workflow
cat("\nData structure preview for rWCVP name resolution:\n")
gbifSEAsiaMammalOccDataCleaned %>% 
  filter(!is.na(gen), !is.na(sp)) %>%
  select(family, gen, sp, authority, ISLAND, COUNTRY) %>%
  slice_head(n = 5) %>%
  print()

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/standardised_occ_data/", "mammalsOccDataStandardised_", date_stamp, ".csv")

write_csv(gbifSEAsiaMammalOccDataCleaned, output_filename)
cat("Dataset saved as:", output_filename, "\n")
```

# Birds

```{r}
# Import downloaded data ----
# Replace these with your actual download keys once downloads are complete
download_keys <- list(
  papua_barat = "0074664-251120083545085",
  papua = "0074663-251120083545085", 
  png = "0074665-251120083545085"
)

# Function to import and process regional data
import_and_process_region <- function(download_key, island, country) {
  # Import data
  data <- occ_download_get(download_key, overwrite = TRUE) %>%
    occ_download_import(na.strings = c("", NA))
  
  # Select relevant columns and add geographic identifiers
  processed_data <- data %>%
    select(gbifID, license, institutionCode, collectionCode, occurrenceID, 
           catalogNumber, recordNumber, recordedBy, eventDate, habitat, 
           eventRemarks, locality, decimalLatitude, decimalLongitude, 
           coordinateUncertaintyInMeters, coordinatePrecision, identifiedBy, 
           scientificName, kingdom, phylum, class, order, family, genus, 
           taxonRank, taxonomicStatus, elevation, elevationAccuracy, issue, 
           taxonKey, acceptedTaxonKey, speciesKey, species, acceptedScientificName, 
           verbatimScientificName, iucnRedListCategory, countryCode, 
           individualCount, year, basisOfRecord, datasetName, establishmentMeans, 
           references) %>%
    # COMPREHENSIVE data type standardization - convert ALL columns to expected types
    mutate(
      # Convert ALL potentially problematic columns to character first, then to proper type
      across(everything(), as.character)
    ) %>%
    # Now convert to proper types where needed
    mutate(
      # Numeric columns 
      decimalLatitude = as.numeric(decimalLatitude),
      decimalLongitude = as.numeric(decimalLongitude),
      coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters),
      coordinatePrecision = as.numeric(coordinatePrecision),
      elevation = as.numeric(elevation),
      elevationAccuracy = as.numeric(elevationAccuracy),
      individualCount = as.numeric(individualCount),
      year = as.numeric(year),
      
      # Keep ID columns as character (safer than bit64)
      gbifID = as.character(gbifID),
      taxonKey = as.character(taxonKey),
      acceptedTaxonKey = as.character(acceptedTaxonKey),
      speciesKey = as.character(speciesKey),
      
      # All other columns remain as character (including issue, license, eventDate, etc.)
    ) %>%
    add_column(ISLAND = island, COUNTRY = country)
  
  cat("Processed", island, "-", country, ":", nrow(processed_data), "records\n")
  return(processed_data)
}

# Define island and country assignments
region_metadata <- list(
  papua = list(island = "New Guinea", country = "Indonesian Papua"),
  papua_barat = list(island = "New Guinea", country = "Indonesian Papua"),
  png = list(island = "New Guinea", country = "Papua New Guinea")
)

# Import and process all regional datasets
cat("Importing and processing regional datasets...\n")

# Process each dataset individually with error handling
regional_datasets <- list()
for (region_name in names(download_keys)) {
  tryCatch({
    regional_datasets[[region_name]] <- import_and_process_region(
      download_keys[[region_name]], 
      region_metadata[[region_name]]$island,
      region_metadata[[region_name]]$country
    )
  }, error = function(e) {
    cat("Error processing", region_name, ":", e$message, "\n")
    regional_datasets[[region_name]] <<- NULL
  })
}

# Remove any NULL entries (failed downloads)
regional_datasets <- regional_datasets[!sapply(regional_datasets, is.null)]

cat("Successfully processed", length(regional_datasets), "regional datasets\n")

# Combine all regional datasets
cat("Combining datasets from all regions...\n")

# Additional safety check - examine data types before combining
cat("Checking data types for consistency...\n")
for (i in seq_along(regional_datasets)) {
  region_name <- names(regional_datasets)[i]
  cat("Dataset", i, "(", region_name, "):\n")
  
  # Check for problematic columns that have caused issues
  problematic_cols <- c("issue", "license", "eventDate")
  for (col in problematic_cols) {
    if (col %in% names(regional_datasets[[i]])) {
      col_type <- class(regional_datasets[[i]][[col]])[1]
      cat("  ", col, ":", col_type, "\n")
    }
  }
}

# Combine datasets (should work smoothly now with standardized types)
gbifSEAsiaBirdOccData <- bind_rows(regional_datasets)

cat("Successfully combined", nrow(gbifSEAsiaBirdOccData), "records from", length(regional_datasets), "regions\n")

# Optional: Check for any remaining data type issues
cat("Data summary by column type:\n")
gbifSEAsiaBirdOccData %>% 
  summarise(across(everything(), ~class(.)[1])) %>% 
  pivot_longer(everything(), names_to = "column", values_to = "type") %>%
  count(type) %>%
  print()

# Clean and standardize GBIF data ----
gbifSEAsiaBirdOccDataCleaned <- gbifSEAsiaBirdOccData %>%
  # Parse accepted scientific name into components
  # Note: Many records will only have genus, or genus + species, without authority
  # This generates expected warnings for records missing some components
  separate(acceptedScientificName, 
           into = c("gen", "sp", "authority"), 
           sep = " ", 
           extra = "merge",
           fill = "right") %>%  # Fill missing pieces with NA (suppresses warnings)
  # Standardize column names to match internal dataset
  rename(collector = recordedBy,
         number = recordNumber,
         lat = decimalLatitude,
         long = decimalLongitude) %>%
  # Select core columns for modeling PLUS geographic metadata for analyses
  select(family, gen, sp, authority, collector, number, lat, long, 
         countryCode, year, coordinateUncertaintyInMeters, coordinatePrecision,
         taxonRank, ISLAND, COUNTRY)

# Quick data quality check
cat("GBIF data summary after cleaning:\n")
cat("Total records:", nrow(gbifSEAsiaBirdOccDataCleaned), "\n")
cat("Records with genus:", sum(!is.na(gbifSEAsiaBirdOccDataCleaned$gen)), "\n")
cat("Records with species:", sum(!is.na(gbifSEAsiaBirdOccDataCleaned$sp)), "\n") 
cat("Records with authority:", sum(!is.na(gbifSEAsiaBirdOccDataCleaned$authority)), "\n")
cat("Records with coordinates:", sum(!is.na(gbifSEAsiaBirdOccDataCleaned$lat) & !is.na(gbifSEAsiaBirdOccDataCleaned$long)), "\n")


# Summary statistics ----
cat("Dataset summary:\n")
cat("Total GBIF records:", nrow(gbifSEAsiaBirdOccDataCleaned), "\n")
cat("Unique species:", gbifSEAsiaBirdOccDataCleaned %>% 
      filter(!is.na(gen), !is.na(sp)) %>% 
      distinct(gen, sp) %>% 
      nrow(), "\n")

# Geographic distribution summary
cat("\nGeographic distribution:\n")
gbifSEAsiaBirdOccDataCleaned %>% 
  filter(!is.na(ISLAND)) %>% 
  count(ISLAND, COUNTRY, sort = TRUE) %>%
  print()

# Preview the data structure for rWCVP workflow
cat("\nData structure preview for rWCVP name resolution:\n")
gbifSEAsiaBirdOccDataCleaned %>% 
  filter(!is.na(gen), !is.na(sp)) %>%
  select(family, gen, sp, authority, ISLAND, COUNTRY) %>%
  slice_head(n = 5) %>%
  print()

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/standardised_occ_data/", "birdsOccDataStandardised_", date_stamp, ".csv")

write_csv(gbifSEAsiaBirdOccDataCleaned, output_filename)
cat("Dataset saved as:", output_filename, "\n")
```

# Squamates

```{R}
# Import downloaded data ----
# Replace these with your actual download keys once downloads are complete
download_keys <- list(
  papua_barat = "0074863-251120083545085",
  papua = "0074862-251120083545085", 
  png = "0074865-251120083545085"
)

# Function to import and process regional data
import_and_process_region <- function(download_key, island, country) {
  # Import data
  data <- occ_download_get(download_key, overwrite = TRUE) %>%
    occ_download_import(na.strings = c("", NA))
  
  # Select relevant columns and add geographic identifiers
  processed_data <- data %>%
    select(gbifID, license, institutionCode, collectionCode, occurrenceID, 
           catalogNumber, recordNumber, recordedBy, eventDate, habitat, 
           eventRemarks, locality, decimalLatitude, decimalLongitude, 
           coordinateUncertaintyInMeters, coordinatePrecision, identifiedBy, 
           scientificName, kingdom, phylum, class, order, family, genus, 
           taxonRank, taxonomicStatus, elevation, elevationAccuracy, issue, 
           taxonKey, acceptedTaxonKey, speciesKey, species, acceptedScientificName, 
           verbatimScientificName, iucnRedListCategory, countryCode, 
           individualCount, year, basisOfRecord, datasetName, establishmentMeans, 
           references) %>%
    # COMPREHENSIVE data type standardization - convert ALL columns to expected types
    mutate(
      # Convert ALL potentially problematic columns to character first, then to proper type
      across(everything(), as.character)
    ) %>%
    # Now convert to proper types where needed
    mutate(
      # Numeric columns 
      decimalLatitude = as.numeric(decimalLatitude),
      decimalLongitude = as.numeric(decimalLongitude),
      coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters),
      coordinatePrecision = as.numeric(coordinatePrecision),
      elevation = as.numeric(elevation),
      elevationAccuracy = as.numeric(elevationAccuracy),
      individualCount = as.numeric(individualCount),
      year = as.numeric(year),
      
      # Keep ID columns as character (safer than bit64)
      gbifID = as.character(gbifID),
      taxonKey = as.character(taxonKey),
      acceptedTaxonKey = as.character(acceptedTaxonKey),
      speciesKey = as.character(speciesKey),
      
      # All other columns remain as character (including issue, license, eventDate, etc.)
    ) %>%
    add_column(ISLAND = island, COUNTRY = country)
  
  cat("Processed", island, "-", country, ":", nrow(processed_data), "records\n")
  return(processed_data)
}

# Define island and country assignments
region_metadata <- list(
  papua = list(island = "New Guinea", country = "Indonesian Papua"),
  papua_barat = list(island = "New Guinea", country = "Indonesian Papua"),
  png = list(island = "New Guinea", country = "Papua New Guinea")
)

# Import and process all regional datasets
cat("Importing and processing regional datasets...\n")

# Process each dataset individually with error handling
regional_datasets <- list()
for (region_name in names(download_keys)) {
  tryCatch({
    regional_datasets[[region_name]] <- import_and_process_region(
      download_keys[[region_name]], 
      region_metadata[[region_name]]$island,
      region_metadata[[region_name]]$country
    )
  }, error = function(e) {
    cat("Error processing", region_name, ":", e$message, "\n")
    regional_datasets[[region_name]] <<- NULL
  })
}

# Remove any NULL entries (failed downloads)
regional_datasets <- regional_datasets[!sapply(regional_datasets, is.null)]

cat("Successfully processed", length(regional_datasets), "regional datasets\n")

# Combine all regional datasets
cat("Combining datasets from all regions...\n")

# Additional safety check - examine data types before combining
cat("Checking data types for consistency...\n")
for (i in seq_along(regional_datasets)) {
  region_name <- names(regional_datasets)[i]
  cat("Dataset", i, "(", region_name, "):\n")
  
  # Check for problematic columns that have caused issues
  problematic_cols <- c("issue", "license", "eventDate")
  for (col in problematic_cols) {
    if (col %in% names(regional_datasets[[i]])) {
      col_type <- class(regional_datasets[[i]][[col]])[1]
      cat("  ", col, ":", col_type, "\n")
    }
  }
}

# Combine datasets (should work smoothly now with standardized types)
gbifSEAsiaSquamateOccData <- bind_rows(regional_datasets)

cat("Successfully combined", nrow(gbifSEAsiaSquamateOccData), "records from", length(regional_datasets), "regions\n")

# Optional: Check for any remaining data type issues
cat("Data summary by column type:\n")
gbifSEAsiaSquamateOccData %>% 
  summarise(across(everything(), ~class(.)[1])) %>% 
  pivot_longer(everything(), names_to = "column", values_to = "type") %>%
  count(type) %>%
  print()

# Clean and standardize GBIF data ----
gbifSEAsiaSquamateOccDataCleaned <- gbifSEAsiaSquamateOccData %>%
  # Parse accepted scientific name into components
  # Note: Many records will only have genus, or genus + species, without authority
  # This generates expected warnings for records missing some components
  separate(acceptedScientificName, 
           into = c("gen", "sp", "authority"), 
           sep = " ", 
           extra = "merge",
           fill = "right") %>%  # Fill missing pieces with NA (suppresses warnings)
  # Standardize column names to match internal dataset
  rename(collector = recordedBy,
         number = recordNumber,
         lat = decimalLatitude,
         long = decimalLongitude) %>%
  # Select core columns for modeling PLUS geographic metadata for analyses
  select(family, gen, sp, authority, collector, number, lat, long, 
         countryCode, year, coordinateUncertaintyInMeters, coordinatePrecision,
         taxonRank, ISLAND, COUNTRY)

# Quick data quality check
cat("GBIF data summary after cleaning:\n")
cat("Total records:", nrow(gbifSEAsiaSquamateOccDataCleaned), "\n")
cat("Records with genus:", sum(!is.na(gbifSEAsiaSquamateOccDataCleaned$gen)), "\n")
cat("Records with species:", sum(!is.na(gbifSEAsiaSquamateOccDataCleaned$sp)), "\n") 
cat("Records with authority:", sum(!is.na(gbifSEAsiaSquamateOccDataCleaned$authority)), "\n")
cat("Records with coordinates:", sum(!is.na(gbifSEAsiaSquamateOccDataCleaned$lat) & !is.na(gbifSEAsiaSquamateOccDataCleaned$long)), "\n")


# Summary statistics ----
cat("Dataset summary:\n")
cat("Total GBIF records:", nrow(gbifSEAsiaSquamateOccDataCleaned), "\n")
cat("Unique species:", gbifSEAsiaSquamateOccDataCleaned %>% 
      filter(!is.na(gen), !is.na(sp)) %>% 
      distinct(gen, sp) %>% 
      nrow(), "\n")

# Geographic distribution summary
cat("\nGeographic distribution:\n")
gbifSEAsiaSquamateOccDataCleaned %>% 
  filter(!is.na(ISLAND)) %>% 
  count(ISLAND, COUNTRY, sort = TRUE) %>%
  print()

# Preview the data structure for rWCVP workflow
cat("\nData structure preview for rWCVP name resolution:\n")
gbifSEAsiaSquamateOccDataCleaned %>% 
  filter(!is.na(gen), !is.na(sp)) %>%
  select(family, gen, sp, authority, ISLAND, COUNTRY) %>%
  slice_head(n = 5) %>%
  print()

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/standardised_occ_data/", "squamatesOccDataStandardised_", date_stamp, ".csv")

write_csv(gbifSEAsiaSquamateOccDataCleaned, output_filename)
cat("Dataset saved as:", output_filename, "\n")
```

# Vascualar plants

```{R}
# Import downloaded data ----
# Replace these with your actual download keys once downloads are complete
download_keys <- list(
  papua_barat = "0074957-251120083545085",
  papua = "0074956-251120083545085", 
  png = "0074958-251120083545085"
)

# Function to import and process regional data
import_and_process_region <- function(download_key, island, country) {
  # Import data
  data <- occ_download_get(download_key, overwrite = TRUE) %>%
    occ_download_import(na.strings = c("", NA))
  
  # Select relevant columns and add geographic identifiers
  processed_data <- data %>%
    select(gbifID, license, institutionCode, collectionCode, occurrenceID, 
           catalogNumber, recordNumber, recordedBy, eventDate, habitat, 
           eventRemarks, locality, decimalLatitude, decimalLongitude, 
           coordinateUncertaintyInMeters, coordinatePrecision, identifiedBy, 
           scientificName, kingdom, phylum, class, order, family, genus, 
           taxonRank, taxonomicStatus, elevation, elevationAccuracy, issue, 
           taxonKey, acceptedTaxonKey, speciesKey, species, acceptedScientificName, 
           verbatimScientificName, iucnRedListCategory, countryCode, 
           individualCount, year, basisOfRecord, datasetName, establishmentMeans, 
           references) %>%
    # COMPREHENSIVE data type standardization - convert ALL columns to expected types
    mutate(
      # Convert ALL potentially problematic columns to character first, then to proper type
      across(everything(), as.character)
    ) %>%
    # Now convert to proper types where needed
    mutate(
      # Numeric columns 
      decimalLatitude = as.numeric(decimalLatitude),
      decimalLongitude = as.numeric(decimalLongitude),
      coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters),
      coordinatePrecision = as.numeric(coordinatePrecision),
      elevation = as.numeric(elevation),
      elevationAccuracy = as.numeric(elevationAccuracy),
      individualCount = as.numeric(individualCount),
      year = as.numeric(year),
      
      # Keep ID columns as character (safer than bit64)
      gbifID = as.character(gbifID),
      taxonKey = as.character(taxonKey),
      acceptedTaxonKey = as.character(acceptedTaxonKey),
      speciesKey = as.character(speciesKey),
      
      # All other columns remain as character (including issue, license, eventDate, etc.)
    ) %>%
    add_column(ISLAND = island, COUNTRY = country)
  
  cat("Processed", island, "-", country, ":", nrow(processed_data), "records\n")
  return(processed_data)
}

# Define island and country assignments
region_metadata <- list(
  papua = list(island = "New Guinea", country = "Indonesia"),
  papua_barat = list(island = "New Guinea", country = "Indonesia"),
  png = list(island = "New Guinea", country = "Papua New Guinea")
)

# Import and process all regional datasets
cat("Importing and processing regional datasets...\n")

# Process each dataset individually with error handling
regional_datasets <- list()
for (region_name in names(download_keys)) {
  tryCatch({
    regional_datasets[[region_name]] <- import_and_process_region(
      download_keys[[region_name]], 
      region_metadata[[region_name]]$island,
      region_metadata[[region_name]]$country
    )
  }, error = function(e) {
    cat("Error processing", region_name, ":", e$message, "\n")
    regional_datasets[[region_name]] <<- NULL
  })
}

# Remove any NULL entries (failed downloads)
regional_datasets <- regional_datasets[!sapply(regional_datasets, is.null)]

cat("Successfully processed", length(regional_datasets), "regional datasets\n")

# Combine all regional datasets
cat("Combining datasets from all regions...\n")

# Additional safety check - examine data types before combining
cat("Checking data types for consistency...\n")
for (i in seq_along(regional_datasets)) {
  region_name <- names(regional_datasets)[i]
  cat("Dataset", i, "(", region_name, "):\n")
  
  # Check for problematic columns that have caused issues
  problematic_cols <- c("issue", "license", "eventDate")
  for (col in problematic_cols) {
    if (col %in% names(regional_datasets[[i]])) {
      col_type <- class(regional_datasets[[i]][[col]])[1]
      cat("  ", col, ":", col_type, "\n")
    }
  }
}

# Combine datasets (should work smoothly now with standardized types)
gbifSEAsiaPlantOccData <- bind_rows(regional_datasets)

cat("Successfully combined", nrow(gbifSEAsiaPlantOccData), "records from", length(regional_datasets), "regions\n")

# Optional: Check for any remaining data type issues
cat("Data summary by column type:\n")
gbifSEAsiaPlantOccData %>% 
  summarise(across(everything(), ~class(.)[1])) %>% 
  pivot_longer(everything(), names_to = "column", values_to = "type") %>%
  count(type) %>%
  print()

# Clean and standardize GBIF data ----
gbifSEAsiaPlantOccDataCleaned <- gbifSEAsiaPlantOccData %>%
  # Parse accepted scientific name into components
  # Note: Many records will only have genus, or genus + species, without authority
  # This generates expected warnings for records missing some components
  separate(acceptedScientificName, 
           into = c("gen", "sp", "authority"), 
           sep = " ", 
           extra = "merge",
           fill = "right") %>%  # Fill missing pieces with NA (suppresses warnings)
  # Standardize column names to match internal dataset
  rename(collector = recordedBy,
         number = recordNumber,
         lat = decimalLatitude,
         long = decimalLongitude) %>%
  # Select core columns for modeling PLUS geographic metadata for analyses
  select(family, gen, sp, authority, collector, number, lat, long, 
         countryCode, year, coordinateUncertaintyInMeters, coordinatePrecision,
         taxonRank, ISLAND, COUNTRY)

# Quick data quality check
cat("GBIF data summary after cleaning:\n")
cat("Total records:", nrow(gbifSEAsiaPlantOccDataCleaned), "\n")
cat("Records with genus:", sum(!is.na(gbifSEAsiaPlantOccDataCleaned$gen)), "\n")
cat("Records with species:", sum(!is.na(gbifSEAsiaPlantOccDataCleaned$sp)), "\n") 
cat("Records with authority:", sum(!is.na(gbifSEAsiaPlantOccDataCleaned$authority)), "\n")
cat("Records with coordinates:", sum(!is.na(gbifSEAsiaPlantOccDataCleaned$lat) & !is.na(gbifSEAsiaPlantOccDataCleaned$long)), "\n")


# Summary statistics ----
cat("Dataset summary:\n")
cat("Total GBIF records:", nrow(gbifSEAsiaPlantOccDataCleaned), "\n")
cat("Unique species:", gbifSEAsiaPlantOccDataCleaned %>% 
      filter(!is.na(gen), !is.na(sp)) %>% 
      distinct(gen, sp) %>% 
      nrow(), "\n")

# Geographic distribution summary
cat("\nGeographic distribution:\n")
gbifSEAsiaPlantOccDataCleaned %>% 
  filter(!is.na(ISLAND)) %>% 
  count(ISLAND, COUNTRY, sort = TRUE) %>%
  print()

# Preview the data structure for rWCVP workflow
cat("\nData structure preview for rWCVP name resolution:\n")
gbifSEAsiaPlantOccDataCleaned %>% 
  filter(!is.na(gen), !is.na(sp)) %>%
  select(family, gen, sp, authority, ISLAND, COUNTRY) %>%
  slice_head(n = 5) %>%
  print()

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/standardised_occ_data/", "plantsOccDataStandardised_", date_stamp, ".csv")

write_csv(gbifSEAsiaPlantOccDataCleaned, output_filename)
cat("Dataset saved as:", output_filename, "\n")
```


## CLEAN DATASET

# Frogs

```{r}
# Specimen collection raster #

# Load raw occurrence data ----
# Import the combined raw dataset from GBIF download script
cat("Loading raw occurrence data...\n")
frogSEAsiaOcc <- read_csv("standardised_occ_data/frogsOccDataStandardised_20260108.csv")

cat("Loaded dataset:", nrow(frogSEAsiaOcc), "records\n")
#cat("Sources:", paste(unique(combined_occurrences$source), collapse = ", "), "\n")

# Generate today's date stamp for output files ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
cat("Output files will use date stamp:", date_stamp, "\n")

# Initial data preparation ----
cat("Starting data cleaning pipeline...\n")
cat("Initial combined dataset:", nrow(frogSEAsiaOcc), "records\n")

# Step 1: Basic geographic and completeness filtering ----
frogSEAsiaOcc1 <- frogSEAsiaOcc %>%
  # Remove records without coordinates
  filter(!is.na(lat), !is.na(long)) %>%
  # Filter to target countries (allowing NA for Kew data which we'll validate spatially)
  filter(countryCode %in% c("ID", "PG"))

cat("After basic filtering:", nrow(frogSEAsiaOcc1), "records remaining\n")

# Step 2: CoordinateCleaner quality checks ----
# Apply comprehensive coordinate cleaning using CoordinateCleaner
# Note: CoordinateCleaner functions need explicit column specification when using non-default names

frogSEAsiaOcc2 <- frogSEAsiaOcc1 %>%
  # Create temporary species column for CoordinateCleaner (cc_dupl needs this)
  mutate(species = if_else(!is.na(gen) & !is.na(sp), paste(gen, sp), NA_character_)) %>%
  # Apply coordinate cleaning tests with explicit column specifications
  cc_dupl(lon = "long", lat = "lat") %>%                    # Remove duplicate records within species
  cc_zero(lon = "long", lat = "lat") %>%                    # Remove records at 0,0 coordinates  
  cc_equ(lon = "long", lat = "lat") %>%                     # Remove records with equal lat/long
  cc_val(lon = "long", lat = "lat") %>%                     # Remove records with invalid coordinates
  #cc_sea(lon = "long", lat = "lat", scale = 50) %>%         # Remove marine records (scale 50 for island detail)
  cc_cap(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country capitals
  cc_cen(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country centroids
  cc_gbif(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near GBIF headquarters
  cc_inst(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near institutions
  # Remove the temporary species column (we'll recreate it later for rWCVP)
  select(-species)

cat("After CoordinateCleaner filtering:", nrow(frogSEAsiaOcc2), "records remaining\n")
cat("Records removed by coordinate cleaning:", 
    nrow(frogSEAsiaOcc1) - nrow(frogSEAsiaOcc2), "\n")

# Step 2.5: Spatial filtering to study area boundaries ----
# Remove Kew records that fall outside New Guinea and Borneo study area
cat("Loading study area boundaries...\n")
study_area <- st_read("PNGIDP.shp")

# Convert occurrence data to spatial points
frogSEAsiaOcc2SF <- frogSEAsiaOcc2 %>%
  filter(!is.na(lat), !is.na(long)) %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326)

# Perform spatial intersection to keep only records within study area
records_in_study_area <- st_intersection(frogSEAsiaOcc2SF, study_area)

# Convert back to regular dataframe and restore lat/long columns
frogSEAsiaOcc2_5 <- records_in_study_area %>%
  # Extract coordinates back to columns
  mutate(
    long = st_coordinates(.)[,1],
    lat = st_coordinates(.)[,2]
  ) %>%
  # Remove geometry column
  st_drop_geometry()

cat("After spatial filtering to study area:", nrow(frogSEAsiaOcc2_5), "records remaining\n")
cat("Records removed by spatial filtering:", 
    nrow(frogSEAsiaOcc2) - nrow(frogSEAsiaOcc2_5), "\n")


# Step 5: Taxonomic filtering ----
# Filter for species-level identifications and clean uncertain identifications
frogSEAsiaOcc5 <- frogSEAsiaOcc2_5 %>%
  filter(
    # Keep records with genus and species information
    !is.na(gen), !is.na(sp),
    # Remove uncertain identifications (cf., aff., sp.)
    !grepl("\\bsp\\.?$|\\bcf\\.?\\b|\\baff\\.?\\b", sp, ignore.case = TRUE)
    # Note: taxonRank column not available in simplified dataset
  )

cat("After taxonomic filtering:", nrow(frogSEAsiaOcc5), "records remaining\n")

cat("Geographic filtering already completed during download phase\n")

# Final cleaning summary ----
frogSEAsiaOccData <- frogSEAsiaOcc5

cat("\n=== CLEANING SUMMARY ===\n")
cat("Original records:", nrow(frogSEAsiaOcc), "\n")
cat("Final cleaned records:", nrow(frogSEAsiaOccData), "\n")
cat("Total removed:", nrow(frogSEAsiaOcc) - nrow(frogSEAsiaOccData), "\n")
cat("Retention rate:", round(nrow(frogSEAsiaOccData)/nrow(frogSEAsiaOcc)*100, 1), "%\n")

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/cleaned_occ_data/", "frogsOccDataCleaned_", date_stamp, ".csv")

write_csv(frogSEAsiaOccData, output_filename)
cat("Dataset saved as:", output_filename, "\n")

```

# Mammals

```{r}
# Specimen collection raster #

# Load raw occurrence data ----
# Import the combined raw dataset from GBIF download script
cat("Loading raw occurrence data...\n")
mammalSEAsiaOcc <- read_csv("standardised_occ_data/mammalsOccDataStandardised_20260108.csv")

cat("Loaded dataset:", nrow(mammalSEAsiaOcc), "records\n")
#cat("Sources:", paste(unique(combined_occurrences$source), collapse = ", "), "\n")

# Generate today's date stamp for output files ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
cat("Output files will use date stamp:", date_stamp, "\n")

# Initial data preparation ----
cat("Starting data cleaning pipeline...\n")
cat("Initial combined dataset:", nrow(mammalSEAsiaOcc), "records\n")

# Step 1: Basic geographic and completeness filtering ----
mammalSEAsiaOcc1 <- mammalSEAsiaOcc %>%
  # Remove records without coordinates
  filter(!is.na(lat), !is.na(long)) %>%
  # Filter to target countries (allowing NA for Kew data which we'll validate spatially)
  filter(countryCode %in% c("ID", "PG"))

cat("After basic filtering:", nrow(mammalSEAsiaOcc1), "records remaining\n")

# Step 2: CoordinateCleaner quality checks ----
# Apply comprehensive coordinate cleaning using CoordinateCleaner
# Note: CoordinateCleaner functions need explicit column specification when using non-default names

mammalSEAsiaOcc2 <- mammalSEAsiaOcc1 %>%
  # Create temporary species column for CoordinateCleaner (cc_dupl needs this)
  mutate(species = if_else(!is.na(gen) & !is.na(sp), paste(gen, sp), NA_character_)) %>%
  # Apply coordinate cleaning tests with explicit column specifications
  cc_dupl(lon = "long", lat = "lat") %>%                    # Remove duplicate records
  cc_zero(lon = "long", lat = "lat") %>%                    # Remove records at 0,0 coordinates  
  cc_equ(lon = "long", lat = "lat") %>%                     # Remove records with equal lat/long
  cc_val(lon = "long", lat = "lat") %>%                     # Remove records with invalid coordinates
  #cc_sea(lon = "long", lat = "lat", scale = 50) %>%         # Remove marine records (scale 50 for island detail)
  cc_cap(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country capitals
  cc_cen(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country centroids
  cc_gbif(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near GBIF headquarters
  cc_inst(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near institutions
  # Remove the temporary species column (we'll recreate it later for rWCVP)
  select(-species)

cat("After CoordinateCleaner filtering:", nrow(mammalSEAsiaOcc2), "records remaining\n")
cat("Records removed by coordinate cleaning:", 
    nrow(mammalSEAsiaOcc1) - nrow(mammalSEAsiaOcc2), "\n")

# Step 2.5: Spatial filtering to study area boundaries ----
# Remove Kew records that fall outside New Guinea and Borneo study area
cat("Loading study area boundaries...\n")
study_area <- st_read("PNGIDP.shp")

# Convert occurrence data to spatial points
mammalSEAsiaOcc2SF <- mammalSEAsiaOcc2 %>%
  filter(!is.na(lat), !is.na(long)) %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326)

# Perform spatial intersection to keep only records within study area
records_in_study_area <- st_intersection(mammalSEAsiaOcc2SF, study_area)

# Convert back to regular dataframe and restore lat/long columns
mammalSEAsiaOcc2_5 <- records_in_study_area %>%
  # Extract coordinates back to columns
  mutate(
    long = st_coordinates(.)[,1],
    lat = st_coordinates(.)[,2]
  ) %>%
  # Remove geometry column
  st_drop_geometry()

cat("After spatial filtering to study area:", nrow(mammalSEAsiaOcc2_5), "records remaining\n")
cat("Records removed by spatial filtering:", 
    nrow(mammalSEAsiaOcc2) - nrow(mammalSEAsiaOcc2_5), "\n")


# Step 5: Taxonomic filtering ----
# Filter for species-level identifications and clean uncertain identifications
mammalSEAsiaOcc5 <- mammalSEAsiaOcc2_5 %>%
  filter(
    # Keep records with genus and species information
    !is.na(gen), !is.na(sp),
    # Remove uncertain identifications (cf., aff., sp.)
    !grepl("\\bsp\\.?$|\\bcf\\.?\\b|\\baff\\.?\\b", sp, ignore.case = TRUE)
    # Note: taxonRank column not available in simplified dataset
  )

cat("After taxonomic filtering:", nrow(mammalSEAsiaOcc5), "records remaining\n")

cat("Geographic filtering already completed during download phase\n")

# Final cleaning summary ----
mammalSEAsiaOccData <- mammalSEAsiaOcc5

cat("\n=== CLEANING SUMMARY ===\n")
cat("Original records:", nrow(mammalSEAsiaOcc), "\n")
cat("Final cleaned records:", nrow(mammalSEAsiaOccData), "\n")
cat("Total removed:", nrow(mammalSEAsiaOcc) - nrow(mammalSEAsiaOccData), "\n")
cat("Retention rate:", round(nrow(mammalSEAsiaOccData)/nrow(mammalSEAsiaOcc)*100, 1), "%\n")

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/cleaned_occ_data/", "mammalsOccDataCleaned_", date_stamp, ".csv")

write_csv(mammalSEAsiaOccData, output_filename)
cat("Dataset saved as:", output_filename, "\n")

```

# Birds

```{r}
# Specimen collection raster #

# Load raw occurrence data ----
# Import the combined raw dataset from GBIF download script
cat("Loading raw occurrence data...\n")
birdSEAsiaOcc <- read_csv("standardised_occ_data/birdsOccDataStandardised_20260108.csv")

cat("Loaded dataset:", nrow(birdSEAsiaOcc), "records\n")
#cat("Sources:", paste(unique(combined_occurrences$source), collapse = ", "), "\n")

# Generate today's date stamp for output files ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
cat("Output files will use date stamp:", date_stamp, "\n")

# Initial data preparation ----
cat("Starting data cleaning pipeline...\n")
cat("Initial combined dataset:", nrow(birdSEAsiaOcc), "records\n")

# Step 1: Basic geographic and completeness filtering ----
birdSEAsiaOcc1 <- birdSEAsiaOcc %>%
  # Remove records without coordinates
  filter(!is.na(lat), !is.na(long)) %>%
  # Filter to target countries (allowing NA for Kew data which we'll validate spatially)
  filter(countryCode %in% c("ID", "PG"))

cat("After basic filtering:", nrow(birdSEAsiaOcc1), "records remaining\n")

# Step 2: CoordinateCleaner quality checks ----
# Apply comprehensive coordinate cleaning using CoordinateCleaner
# Note: CoordinateCleaner functions need explicit column specification when using non-default names

birdSEAsiaOcc2 <- birdSEAsiaOcc1 %>%
  # Create temporary species column for CoordinateCleaner (cc_dupl needs this)
  mutate(species = if_else(!is.na(gen) & !is.na(sp), paste(gen, sp), NA_character_)) %>%
  # Apply coordinate cleaning tests with explicit column specifications
  cc_dupl(lon = "long", lat = "lat") %>%                    # Remove duplicate records
  cc_zero(lon = "long", lat = "lat") %>%                    # Remove records at 0,0 coordinates  
  cc_equ(lon = "long", lat = "lat") %>%                     # Remove records with equal lat/long
  cc_val(lon = "long", lat = "lat") %>%                     # Remove records with invalid coordinates
  #cc_sea(lon = "long", lat = "lat", scale = 50) %>%         # Remove marine records (scale 50 for island detail)
  cc_cap(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country capitals
  cc_cen(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country centroids
  cc_gbif(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near GBIF headquarters
  cc_inst(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near institutions
  # Remove the temporary species column (we'll recreate it later for rWCVP)
  select(-species)

cat("After CoordinateCleaner filtering:", nrow(birdSEAsiaOcc2), "records remaining\n")
cat("Records removed by coordinate cleaning:", 
    nrow(birdSEAsiaOcc1) - nrow(birdSEAsiaOcc2), "\n")

# Step 2.5: Spatial filtering to study area boundaries ----
# Remove Kew records that fall outside New Guinea and Borneo study area
cat("Loading study area boundaries...\n")
study_area <- st_read("PNGIDP.shp")

# Convert occurrence data to spatial points
birdSEAsiaOcc2SF <- birdSEAsiaOcc2 %>%
  filter(!is.na(lat), !is.na(long)) %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326)

# Perform spatial intersection to keep only records within study area
records_in_study_area <- st_intersection(birdSEAsiaOcc2SF, study_area)

# Convert back to regular dataframe and restore lat/long columns
birdSEAsiaOcc2_5 <- records_in_study_area %>%
  # Extract coordinates back to columns
  mutate(
    long = st_coordinates(.)[,1],
    lat = st_coordinates(.)[,2]
  ) %>%
  # Remove geometry column
  st_drop_geometry()

cat("After spatial filtering to study area:", nrow(birdSEAsiaOcc2_5), "records remaining\n")
cat("Records removed by spatial filtering:", 
    nrow(birdSEAsiaOcc2) - nrow(birdSEAsiaOcc2_5), "\n")


# Step 5: Taxonomic filtering ----
# Filter for species-level identifications and clean uncertain identifications
birdSEAsiaOcc5 <- birdSEAsiaOcc2_5 %>%
  filter(
    # Keep records with genus and species information
    !is.na(gen), !is.na(sp),
    # Remove uncertain identifications (cf., aff., sp.)
    !grepl("\\bsp\\.?$|\\bcf\\.?\\b|\\baff\\.?\\b", sp, ignore.case = TRUE)
    # Note: taxonRank column not available in simplified dataset
  )

cat("After taxonomic filtering:", nrow(birdSEAsiaOcc5), "records remaining\n")

cat("Geographic filtering already completed during download phase\n")

# Final cleaning summary ----
birdSEAsiaOccData <- birdSEAsiaOcc5

cat("\n=== CLEANING SUMMARY ===\n")
cat("Original records:", nrow(birdSEAsiaOcc), "\n")
cat("Final cleaned records:", nrow(birdSEAsiaOccData), "\n")
cat("Total removed:", nrow(birdSEAsiaOcc) - nrow(birdSEAsiaOccData), "\n")
cat("Retention rate:", round(nrow(birdSEAsiaOccData)/nrow(birdSEAsiaOcc)*100, 1), "%\n")

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/cleaned_occ_data/", "birdsOccDataCleaned_", date_stamp, ".csv")

write_csv(birdSEAsiaOccData, output_filename)
cat("Dataset saved as:", output_filename, "\n")

```

# Squamates

```{r}
# Specimen collection raster #

# Load raw occurrence data ----
# Import the combined raw dataset from GBIF download script
cat("Loading raw occurrence data...\n")
squamateSEAsiaOcc <- read_csv("standardised_occ_data/squamatesOccDataStandardised_20260108.csv")

cat("Loaded dataset:", nrow(squamateSEAsiaOcc), "records\n")
#cat("Sources:", paste(unique(combined_occurrences$source), collapse = ", "), "\n")

# Generate today's date stamp for output files ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
cat("Output files will use date stamp:", date_stamp, "\n")

# Initial data preparation ----
cat("Starting data cleaning pipeline...\n")
cat("Initial combined dataset:", nrow(squamateSEAsiaOcc), "records\n")

# Step 1: Basic geographic and completeness filtering ----
squamateSEAsiaOcc1 <- squamateSEAsiaOcc %>%
  # Remove records without coordinates
  filter(!is.na(lat), !is.na(long)) %>%
  # Filter to target countries (allowing NA for Kew data which we'll validate spatially)
  filter(countryCode %in% c("ID", "PG"))

cat("After basic filtering:", nrow(squamateSEAsiaOcc1), "records remaining\n")

# Step 2: CoordinateCleaner quality checks ----
# Apply comprehensive coordinate cleaning using CoordinateCleaner
# Note: CoordinateCleaner functions need explicit column specification when using non-default names

squamateSEAsiaOcc2 <- squamateSEAsiaOcc1 %>%
  # Create temporary species column for CoordinateCleaner (cc_dupl needs this)
  mutate(species = if_else(!is.na(gen) & !is.na(sp), paste(gen, sp), NA_character_)) %>%
  # Apply coordinate cleaning tests with explicit column specifications
  cc_dupl(lon = "long", lat = "lat") %>%                    # Remove duplicate records
  cc_zero(lon = "long", lat = "lat") %>%                    # Remove records at 0,0 coordinates  
  cc_equ(lon = "long", lat = "lat") %>%                     # Remove records with equal lat/long
  cc_val(lon = "long", lat = "lat") %>%                     # Remove records with invalid coordinates
  #cc_sea(lon = "long", lat = "lat", scale = 50) %>%         # Remove marine records (scale 50 for island detail)
  cc_cap(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country capitals
  cc_cen(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country centroids
  cc_gbif(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near GBIF headquarters
  cc_inst(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near institutions
  # Remove the temporary species column (we'll recreate it later for rWCVP)
  select(-species)

cat("After CoordinateCleaner filtering:", nrow(squamateSEAsiaOcc2), "records remaining\n")
cat("Records removed by coordinate cleaning:", 
    nrow(squamateSEAsiaOcc1) - nrow(squamateSEAsiaOcc2), "\n")

# Step 2.5: Spatial filtering to study area boundaries ----
# Remove Kew records that fall outside New Guinea and Borneo study area
cat("Loading study area boundaries...\n")
study_area <- st_read("PNGIDP.shp")

# Convert occurrence data to spatial points
squamateSEAsiaOcc2SF <- squamateSEAsiaOcc2 %>%
  filter(!is.na(lat), !is.na(long)) %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326)

# Perform spatial intersection to keep only records within study area
records_in_study_area <- st_intersection(squamateSEAsiaOcc2SF, study_area)

# Convert back to regular dataframe and restore lat/long columns
squamateSEAsiaOcc2_5 <- records_in_study_area %>%
  # Extract coordinates back to columns
  mutate(
    long = st_coordinates(.)[,1],
    lat = st_coordinates(.)[,2]
  ) %>%
  # Remove geometry column
  st_drop_geometry()

cat("After spatial filtering to study area:", nrow(squamateSEAsiaOcc2_5), "records remaining\n")
cat("Records removed by spatial filtering:", 
    nrow(squamateSEAsiaOcc2) - nrow(squamateSEAsiaOcc2_5), "\n")


# Step 5: Taxonomic filtering ----
# Filter for species-level identifications and clean uncertain identifications
squamateSEAsiaOcc5 <- squamateSEAsiaOcc2_5 %>%
  filter(
    # Keep records with genus and species information
    !is.na(gen), !is.na(sp),
    # Remove uncertain identifications (cf., aff., sp.)
    !grepl("\\bsp\\.?$|\\bcf\\.?\\b|\\baff\\.?\\b", sp, ignore.case = TRUE)
    # Note: taxonRank column not available in simplified dataset
  )

cat("After taxonomic filtering:", nrow(squamateSEAsiaOcc5), "records remaining\n")

cat("Geographic filtering already completed during download phase\n")

# Final cleaning summary ----
squamateSEAsiaOccData <- squamateSEAsiaOcc5

cat("\n=== CLEANING SUMMARY ===\n")
cat("Original records:", nrow(squamateSEAsiaOcc), "\n")
cat("Final cleaned records:", nrow(squamateSEAsiaOccData), "\n")
cat("Total removed:", nrow(squamateSEAsiaOcc) - nrow(squamateSEAsiaOccData), "\n")
cat("Retention rate:", round(nrow(squamateSEAsiaOccData)/nrow(squamateSEAsiaOcc)*100, 1), "%\n")

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/cleaned_occ_data/", "squamatesOccDataCleaned_", date_stamp, ".csv")

write_csv(squamateSEAsiaOccData, output_filename)
cat("Dataset saved as:", output_filename, "\n")

```

# Vascular plants

```{r}
# Specimen collection raster #

# Load raw occurrence data ----
# Import the combined raw dataset from GBIF download script
cat("Loading raw occurrence data...\n")
plantSEAsiaOcc <- read_csv("standardised_occ_data/plantsOccDataStandardised_20260108.csv")

cat("Loaded dataset:", nrow(plantSEAsiaOcc), "records\n")
#cat("Sources:", paste(unique(combined_occurrences$source), collapse = ", "), "\n")

# Generate today's date stamp for output files ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
cat("Output files will use date stamp:", date_stamp, "\n")

# Initial data preparation ----
cat("Starting data cleaning pipeline...\n")
cat("Initial combined dataset:", nrow(plantSEAsiaOcc), "records\n")

# Step 1: Basic geographic and completeness filtering ----
plantSEAsiaOcc1 <- plantSEAsiaOcc %>%
  # Remove records without coordinates
  filter(!is.na(lat), !is.na(long)) %>%
  # Filter to target countries (allowing NA for Kew data which we'll validate spatially)
  filter(countryCode %in% c("ID", "PG","MY","PH","BN","TL"))

cat("After basic filtering:", nrow(plantSEAsiaOcc1), "records remaining\n")

# Step 2: CoordinateCleaner quality checks ----
# Apply comprehensive coordinate cleaning using CoordinateCleaner
# Note: CoordinateCleaner functions need explicit column specification when using non-default names

plantSEAsiaOcc2 <- plantSEAsiaOcc1 %>%
  # Create temporary species column for CoordinateCleaner (cc_dupl needs this)
  mutate(species = if_else(!is.na(gen) & !is.na(sp), paste(gen, sp), NA_character_)) %>%
  # Apply coordinate cleaning tests with explicit column specifications
  cc_dupl(lon = "long", lat = "lat") %>%                    # Remove duplicate records
  cc_zero(lon = "long", lat = "lat") %>%                    # Remove records at 0,0 coordinates  
  cc_equ(lon = "long", lat = "lat") %>%                     # Remove records with equal lat/long
  cc_val(lon = "long", lat = "lat") %>%                     # Remove records with invalid coordinates
  #cc_sea(lon = "long", lat = "lat", scale = 50) %>%         # Remove marine records (scale 50 for island detail)
  cc_cap(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country capitals
  cc_cen(lon = "long", lat = "lat", buffer = 2000) %>%      # Remove records near country centroids
  cc_gbif(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near GBIF headquarters
  cc_inst(lon = "long", lat = "lat", buffer = 2000) %>%     # Remove records near institutions
  # Remove the temporary species column (we'll recreate it later for rWCVP)
  select(-species)

cat("After CoordinateCleaner filtering:", nrow(plantSEAsiaOcc2), "records remaining\n")
cat("Records removed by coordinate cleaning:", 
    nrow(plantSEAsiaOcc1) - nrow(plantSEAsiaOcc2), "\n")

# Step 2.5: Spatial filtering to study area boundaries ----
# Remove Kew records that fall outside New Guinea and Borneo study area
cat("Loading study area boundaries...\n")
study_area <- st_read("PNGIDP.shp")

# Convert occurrence data to spatial points
plantSEAsiaOcc2SF <- plantSEAsiaOcc2 %>%
  filter(!is.na(lat), !is.na(long)) %>%
  st_as_sf(coords = c("long", "lat"), crs = 4326)

# Perform spatial intersection to keep only records within study area
records_in_study_area <- st_intersection(plantSEAsiaOcc2SF, study_area)

# Convert back to regular dataframe and restore lat/long columns
plantSEAsiaOcc2_5 <- records_in_study_area %>%
  # Extract coordinates back to columns
  mutate(
    long = st_coordinates(.)[,1],
    lat = st_coordinates(.)[,2]
  ) %>%
  # Remove geometry column
  st_drop_geometry()

cat("After spatial filtering to study area:", nrow(plantSEAsiaOcc2_5), "records remaining\n")
cat("Records removed by spatial filtering:", 
    nrow(plantSEAsiaOcc2) - nrow(plantSEAsiaOcc2_5), "\n")


# Step 5: Taxonomic filtering ----
# Filter for species-level identifications and clean uncertain identifications
plantSEAsiaOcc5 <- plantSEAsiaOcc2_5 %>%
  filter(
    # Keep records with genus and species information
    !is.na(gen), !is.na(sp),
    # Remove uncertain identifications (cf., aff., sp.)
    !grepl("\\bsp\\.?$|\\bcf\\.?\\b|\\baff\\.?\\b", sp, ignore.case = TRUE)
    # Note: taxonRank column not available in simplified dataset
  )

cat("After taxonomic filtering:", nrow(plantSEAsiaOcc5), "records remaining\n")

cat("Geographic filtering already completed during download phase\n")

# Final cleaning summary ----
plantSEAsiaOccData <- plantSEAsiaOcc5

cat("\n=== CLEANING SUMMARY ===\n")
cat("Original records:", nrow(plantSEAsiaOcc), "\n")
cat("Final cleaned records:", nrow(plantSEAsiaOccData), "\n")
cat("Total removed:", nrow(plantSEAsiaOcc) - nrow(plantSEAsiaOccData), "\n")
cat("Retention rate:", round(nrow(plantSEAsiaOccData)/nrow(plantSEAsiaOcc)*100, 1), "%\n")

# Generate date stamp and save cleaned dataset ----
date_stamp <- format(Sys.Date(), "%Y%m%d")
output_filename <- paste0(getwd(),"/cleaned_occ_data/", "plantsOccDataCleaned_", date_stamp, ".csv")

write_csv(plantSEAsiaOccData, output_filename)
cat("Dataset saved as:", output_filename, "\n")

```


## PLOTTING

# Fig. 1: Heatmaps of occurrence data
# Frogs
```{r}

# species and lat long data
frogSEAsiaCollXY <- frogSEAsiaOccData %>%
  select(gen, sp, long, lat) %>%
  na.omit()

frogSEAsiaCollXY <- frogSEAsiaCollXY |> dplyr::mutate(id = dplyr::row_number(), .before = 1)

# to sf object, specifying variables with coordinates and projection
frogSEAsiaCollSF <- st_as_sf(frogSEAsiaCollXY, coords = c("long", "lat"), crs = 4326) %>%
  group_by(id) %>%
  summarize()

# ------------------------------------------------------------------------------
# 4) Plot
# ------------------------------------------------------------------------------
# Countries (Papua New Guinea only)
countries <- ne_countries(scale = "large", returnclass = "sf")

png <- countries %>%
  filter(name == "Papua New Guinea")

# Indonesian provinces
states <- ne_states(country = "Indonesia",
                    returnclass = "sf")

papua_id <- states %>%
  filter(name %in% c("Papua", "Papua Barat"))

png2 <- png %>%
  transmute(
    unit = name,          # "Papua New Guinea"
    geom = geometry
  ) %>%
  st_as_sf()

papua2 <- papua_id %>%
  transmute(
    unit = name,          # "Papua", "Papua Barat"
    geom = geometry
  ) %>%
  st_as_sf()

new_guinea <- bind_rows(
  st_make_valid(png2),
  st_make_valid(papua2)
)


# (Optional) dissolve borders into a single polygon
ng <- new_guinea %>%
  st_union()


regionPoly <- ng |> st_make_valid()

regionGrid <- regionPoly |>
  st_make_grid(cellsize = 0.3, what = "polygons") |>
  st_intersection(regionPoly) |>
  st_collection_extract("POLYGON") |>
  st_make_valid() |>
  st_sf() |>
  dplyr::mutate(cellid = dplyr::row_number())

gridPlot <-
  ggplot() +
  geom_sf(data = regionPoly) +
  geom_sf(data = regionGrid) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
gridPlot

frogSEAsiaCollSF <- frogSEAsiaCollSF |> st_make_valid()

frogsCollRaster <- regionGrid |>
  st_join(frogSEAsiaCollSF, join = st_intersects) |>
  dplyr::mutate(overlap = ifelse(!is.na(id), 1, 0)) |>
  dplyr::group_by(cellid) |>
  dplyr::summarize(numCollections = sum(overlap), .groups = "drop")

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
frog_bin_levels <- c("0","125","26100","101500")

# Bin + lock factor levels
frogsCollRaster_binned <- frogsCollRaster %>%
  mutate(collection_bin = cut(
    numCollections,
    breaks = c(-Inf, 0, 25, 100, 500),
    labels = frog_bin_levels,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = frog_bin_levels))

# Color palette named by the same levels (note the orange for "15012000")
#pal <- c(
  #"0"          = "#FFFFFF",
  #"125"       = "#EAF2FF",
  #"26100"     = "#D7E9FF",
  #"101500"    = "#C3DEFF",
  #"5011000"   = "#AECFFF",
  #"10011500"  = "#FFF6BF",
  #"15012000"  = "#FFE1B8", 
  #">2000"      = "#FFB6C8"
#)

frog_pal <- c(
  "0" = "#000000",
  "125"      = "#3D3D00",
  "26100"    = "#666600",
  "101500"   = "#8C8C00"
)


frogsCollRasterPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = frogsCollRaster_binned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Occurrences",
    values = frog_pal,
    limits = frog_bin_levels,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = frog_pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )

ggsave(
  filename = "frogSampleLocationsRasterMap.png",  # file name and extension
  plot     = frogsCollRasterPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

# Digitised occurrence density per region

counts <- as.data.frame(table(frogSEAsiaOccData[[13]]))
names(counts) <- c("Region", "Observations")

# I don't know accurate these surface areas are and to what specific borders they exactly apply

areas <- data.frame(
  Region = c("Bali","Brunei","Indonesian Borneo","Indonesian Papua",
             "Java","Lesser Sunda Islands","Malaysian Borneo","Maluku",
             "Papua New Guinea","Phillipines","Sulawesi","Sumatra"),
  Area_km2 = c(5590.15,5765,534698.27,412214.61,132598.77,67128.38 + 14950,
               198445.64,78897,462840,300000,174416.16,482286.55)
)

density_table <- counts %>%
  left_join(areas, by = "Region") %>%
  mutate(Density = Observations / Area_km2)

```

# Mammals

```{r}
## Mammals

# species and lat long data
mammalSEAsiaCollXY <- mammalSEAsiaOccData %>%
  select(gen, sp, long, lat) %>%
  na.omit()

mammalSEAsiaCollXY <- mammalSEAsiaCollXY |> dplyr::mutate(id = dplyr::row_number(), .before = 1)

# to sf object, specifying variables with coordinates and projection
mammalSEAsiaCollSF <- st_as_sf(mammalSEAsiaCollXY, coords = c("long", "lat"), crs = 4326) %>%
  group_by(id) %>%
  summarize()

# ------------------------------------------------------------------------------
# 4) Plot
# ------------------------------------------------------------------------------
# Countries (Papua New Guinea only)
countries <- ne_countries(scale = "large", returnclass = "sf")

png <- countries %>%
  filter(name == "Papua New Guinea")

# Indonesian provinces
states <- ne_states(country = "Indonesia",
                    returnclass = "sf")

papua_id <- states %>%
  filter(name %in% c("Papua", "Papua Barat"))

png2 <- png %>%
  transmute(
    unit = name,          # "Papua New Guinea"
    geom = geometry
  ) %>%
  st_as_sf()

papua2 <- papua_id %>%
  transmute(
    unit = name,          # "Papua", "Papua Barat"
    geom = geometry
  ) %>%
  st_as_sf()

new_guinea <- bind_rows(
  st_make_valid(png2),
  st_make_valid(papua2)
)


# (Optional) dissolve borders into a single polygon
ng <- new_guinea %>%
  st_union()

regionPoly <- ng |> st_make_valid()

regionGrid <- regionPoly |>
  st_make_grid(cellsize = 0.3, what = "polygons") |>
  st_intersection(regionPoly) |>
  st_collection_extract("POLYGON") |>
  st_make_valid() |>
  st_sf() |>
  dplyr::mutate(cellid = dplyr::row_number())

gridPlot <-
  ggplot() +
  geom_sf(data = regionPoly) +
  geom_sf(data = regionGrid) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
gridPlot

mammalSEAsiaCollSF <- mammalSEAsiaCollSF |> st_make_valid()

mammalCollRaster <- regionGrid |>
  st_join(mammalSEAsiaCollSF, join = st_intersects) |>
  dplyr::mutate(overlap = ifelse(!is.na(id), 1, 0)) |>
  dplyr::group_by(cellid) |>
  dplyr::summarize(numCollections = sum(overlap), .groups = "drop")

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
bin_levels <- c("0","125","26100","101500")

# Bin + lock factor levels
mammalCollRaster_binned <- mammalCollRaster %>%
  mutate(collection_bin = cut(
    numCollections,
    breaks = c(-Inf, 0, 25, 100, 500),
    labels = bin_levels,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = bin_levels))

# Color palette named by the same levels (note the orange for "15012000")
#pal <- c(
  #"0"          = "#FFFFFF",
  #"125"       = "#EAF2FF",
  #"26100"     = "#D7E9FF",
  #"101500"    = "#C3DEFF",
  #"5011000"   = "#AECFFF",
  #"10011500"  = "#FFF6BF",
  #"15012000"  = "#FFE1B8", 
  #">2000"      = "#FFB6C8"
#)

palMammals <- c(
  "0" = "#000000",
  "125"      = "#3D3D00",
  "26100"    = "#666600",
  "101500"   = "#8C8C00"
)


mammalCollRasterPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = mammalCollRaster_binned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Occurrences",
    values = palMammals,
    limits = bin_levels,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )

ggsave(
  filename = "mammalSampleLocationsRasterMap.png",  # file name and extension
  plot     = mammalCollRasterPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

# Digitised occurrence density per region

counts <- as.data.frame(table(mammalSEAsiaOccData[[13]]))
names(counts) <- c("Region", "Observations")

# I don't know accurate these surface areas are and to what specific borders they exactly apply

areas <- data.frame(
  Region = c("Bali","Brunei","Indonesian Borneo","Indonesian Papua",
             "Java","Lesser Sunda Islands","Malaysian Borneo","Maluku",
             "Papua New Guinea","Phillipines","Sulawesi","Sumatra"),
  Area_km2 = c(5590.15,5765,534698.27,412214.61,132598.77,67128.38 + 14950,
               198445.64,78897,462840,300000,174416.16,482286.55)
)

density_table <- counts %>%
  left_join(areas, by = "Region") %>%
  mutate(Density = Observations / Area_km2)

```

# Birds

```{r}
## Birds


# species and lat long data
birdSEAsiaCollXY <- birdSEAsiaOccData %>%
  select(gen, sp, long, lat) %>%
  na.omit()

birdSEAsiaCollXY <- birdSEAsiaCollXY |> dplyr::mutate(id = dplyr::row_number(), .before = 1)

# to sf object, specifying variables with coordinates and projection
birdSEAsiaCollSF <- st_as_sf(birdSEAsiaCollXY, coords = c("long", "lat"), crs = 4326) %>%
  group_by(id) %>%
  summarize()

# ------------------------------------------------------------------------------
# 4) Plot
# ------------------------------------------------------------------------------
# Countries (Papua New Guinea only)
countries <- ne_countries(scale = "large", returnclass = "sf")

png <- countries %>%
  filter(name == "Papua New Guinea")

# Indonesian provinces
states <- ne_states(country = "Indonesia",
                    returnclass = "sf")

papua_id <- states %>%
  filter(name %in% c("Papua", "Papua Barat"))

png2 <- png %>%
  transmute(
    unit = name,          # "Papua New Guinea"
    geom = geometry
  ) %>%
  st_as_sf()

papua2 <- papua_id %>%
  transmute(
    unit = name,          # "Papua", "Papua Barat"
    geom = geometry
  ) %>%
  st_as_sf()

new_guinea <- bind_rows(
  st_make_valid(png2),
  st_make_valid(papua2)
)


# (Optional) dissolve borders into a single polygon
ng <- new_guinea %>%
  st_union()



# plot points
birdCollPlot <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = birdSEAsiaCollSF, col = "yellow", pch = 20, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)

regionPoly <- ng |> st_make_valid()

regionGrid <- regionPoly |>
  st_make_grid(cellsize = 0.3, what = "polygons") |>
  st_intersection(regionPoly) |>
  st_collection_extract("POLYGON") |>
  st_make_valid() |>
  st_sf() |>
  dplyr::mutate(cellid = dplyr::row_number())

gridPlot <-
  ggplot() +
  geom_sf(data = regionPoly) +
  geom_sf(data = regionGrid) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
gridPlot

birdSEAsiaCollSF <- birdSEAsiaCollSF |> st_make_valid()

birdCollRaster <- regionGrid |>
  st_join(birdSEAsiaCollSF, join = st_intersects) |>
  dplyr::mutate(overlap = ifelse(!is.na(id), 1, 0)) |>
  dplyr::group_by(cellid) |>
  dplyr::summarize(numCollections = sum(overlap), .groups = "drop")

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
bin_levels <- c("0","125","26100","101500","5011000",
                "10011500","15012000",">2000")

# Bin + lock factor levels
birdCollRaster_binned <- birdCollRaster %>%
  mutate(collection_bin = cut(
    numCollections,
    breaks = c(-Inf, 0, 25, 100, 500, 1000, 1500, 2000, Inf),
    labels = bin_levels,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = bin_levels))

# Color palette named by the same levels (note the orange for "15012000")
#pal <- c(
  #"0"          = "#FFFFFF",
  #"125"       = "#EAF2FF",
  #"26100"     = "#D7E9FF",
  #"101500"    = "#C3DEFF",
  #"5011000"   = "#AECFFF",
  #"10011500"  = "#FFF6BF",
  #"15012000"  = "#FFE1B8", 
  #">2000"      = "#FFB6C8"
#)

pal <- c(
  "0" = "#000000",
  "125"      = "#3D3D00",
  "26100"    = "#666600",
  "101500"   = "#8C8C00",
  "5011000"  = "#B3B300",
  "10011500" = "#D9D900",
  "15012000" = "#FFFF00",
  ">2000"     = "#FFFF66"
)


birdCollRasterPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = birdCollRaster_binned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Occurrences",
    values = pal,
    limits = bin_levels,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )

ggsave(
  filename = "birdSampleLocationsRasterMap.png",  # file name and extension
  plot     = birdCollRasterPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

# Digitised occurrence density per region

counts <- as.data.frame(table(birdSEAsiaOccData[[13]]))
names(counts) <- c("Region", "Observations")

# I don't know accurate these surface areas are and to what specific borders they exactly apply

areas <- data.frame(
  Region = c("Bali","Brunei","Indonesian Borneo","Indonesian Papua",
             "Java","Lesser Sunda Islands","Malaysian Borneo","Maluku",
             "Papua New Guinea","Phillipines","Sulawesi","Sumatra"),
  Area_km2 = c(5590.15,5765,534698.27,412214.61,132598.77,67128.38 + 14950,
               198445.64,78897,462840,300000,174416.16,482286.55)
)

density_table <- counts %>%
  left_join(areas, by = "Region") %>%
  mutate(Density = Observations / Area_km2)

```

# Squamates

```{r}
## SQUAMATES


# species and lat long data
squamateSEAsiaCollXY <- squamateSEAsiaOccData %>%
  select(gen, sp, long, lat) %>%
  na.omit()

squamateSEAsiaCollXY <- squamateSEAsiaCollXY |> dplyr::mutate(id = dplyr::row_number(), .before = 1)

# to sf object, specifying variables with coordinates and projection
squamateSEAsiaCollSF <- st_as_sf(squamateSEAsiaCollXY, coords = c("long", "lat"), crs = 4326) %>%
  group_by(id) %>%
  summarize()

# ------------------------------------------------------------------------------
# 4) Plot
# ------------------------------------------------------------------------------
# Countries (Papua New Guinea only)
countries <- ne_countries(scale = "large", returnclass = "sf")

png <- countries %>%
  filter(name == "Papua New Guinea")

# Indonesian provinces
states <- ne_states(country = "Indonesia",
                    returnclass = "sf")

papua_id <- states %>%
  filter(name %in% c("Papua", "Papua Barat"))

png2 <- png %>%
  transmute(
    unit = name,          # "Papua New Guinea"
    geom = geometry
  ) %>%
  st_as_sf()

papua2 <- papua_id %>%
  transmute(
    unit = name,          # "Papua", "Papua Barat"
    geom = geometry
  ) %>%
  st_as_sf()

new_guinea <- bind_rows(
  st_make_valid(png2),
  st_make_valid(papua2)
)


# (Optional) dissolve borders into a single polygon
ng <- new_guinea %>%
  st_union()



# plot points
squamateCollPlot <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = squamateSEAsiaCollSF, col = "yellow", pch = 20, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)

regionPoly <- ng |> st_make_valid()

regionGrid <- regionPoly |>
  st_make_grid(cellsize = 0.3, what = "polygons") |>
  st_intersection(regionPoly) |>
  st_collection_extract("POLYGON") |>
  st_make_valid() |>
  st_sf() |>
  dplyr::mutate(cellid = dplyr::row_number())

gridPlot <-
  ggplot() +
  geom_sf(data = regionPoly) +
  geom_sf(data = regionGrid) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
gridPlot

squamateSEAsiaCollSF <- squamateSEAsiaCollSF |> st_make_valid()

squamateCollRaster <- regionGrid |>
  st_join(squamateSEAsiaCollSF, join = st_intersects) |>
  dplyr::mutate(overlap = ifelse(!is.na(id), 1, 0)) |>
  dplyr::group_by(cellid) |>
  dplyr::summarize(numCollections = sum(overlap), .groups = "drop")

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
bin_levels <- c("0","125","26100","101500","5011000")

# Bin + lock factor levels
squamateCollRaster_binned <- squamateCollRaster %>%
  mutate(collection_bin = cut(
    numCollections,
    breaks = c(-Inf, 0, 25, 100, 500, 1000),
    labels = bin_levels,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = bin_levels))

# Color palette named by the same levels (note the orange for "15012000")
#pal <- c(
  #"0"          = "#FFFFFF",
  #"125"       = "#EAF2FF",
  #"26100"     = "#D7E9FF",
  #"101500"    = "#C3DEFF",
  #"5011000"   = "#AECFFF",
  #"10011500"  = "#FFF6BF",
  #"15012000"  = "#FFE1B8", 
  #">2000"      = "#FFB6C8"
#)

pal <- c(
  "0" = "#000000",
  "125"      = "#3D3D00",
  "26100"    = "#666600",
  "101500"   = "#8C8C00",
  "5011000"  = "#B3B300"
)


squamateCollRasterPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = squamateCollRaster_binned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Occurrences",
    values = pal,
    limits = bin_levels,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )

ggsave(
  filename = "squamateSampleLocationsRasterMap.png",  # file name and extension
  plot     = squamateCollRasterPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

# Digitised occurrence density per region

counts <- as.data.frame(table(squamateSEAsiaOccData[[13]]))
names(counts) <- c("Region", "Observations")

# I don't know accurate these surface areas are and to what specific borders they exactly apply

areas <- data.frame(
  Region = c("Bali","Brunei","Indonesian Borneo","Indonesian Papua",
             "Java","Lesser Sunda Islands","Malaysian Borneo","Maluku",
             "Papua New Guinea","Phillipines","Sulawesi","Sumatra"),
  Area_km2 = c(5590.15,5765,534698.27,412214.61,132598.77,67128.38 + 14950,
               198445.64,78897,462840,300000,174416.16,482286.55)
)

density_table <- counts %>%
  left_join(areas, by = "Region") %>%
  mutate(Density = Observations / Area_km2)

```

# Vascular plants

```{r}
## VASCULAR PLANTS

# species and lat long data
plantSEAsiaCollXY <- plantSEAsiaOccData %>%
  select(gen, sp, long, lat) %>%
  na.omit()

plantSEAsiaCollXY <- plantSEAsiaCollXY |> dplyr::mutate(id = dplyr::row_number(), .before = 1)

# to sf object, specifying variables with coordinates and projection
plantSEAsiaCollSF <- st_as_sf(plantSEAsiaCollXY, coords = c("long", "lat"), crs = 4326) %>%
  group_by(id) %>%
  summarize()

# ------------------------------------------------------------------------------
# 4) Plot
# ------------------------------------------------------------------------------
# Countries (Papua New Guinea only)
countries <- ne_countries(scale = "large", returnclass = "sf")

png <- countries %>%
  filter(name == "Papua New Guinea")

# Indonesian provinces
states <- ne_states(country = "Indonesia",
                    returnclass = "sf")

papua_id <- states %>%
  filter(name %in% c("Papua", "Papua Barat"))

png2 <- png %>%
  transmute(
    unit = name,          # "Papua New Guinea"
    geom = geometry
  ) %>%
  st_as_sf()

papua2 <- papua_id %>%
  transmute(
    unit = name,          # "Papua", "Papua Barat"
    geom = geometry
  ) %>%
  st_as_sf()

new_guinea <- bind_rows(
  st_make_valid(png2),
  st_make_valid(papua2)
)


# (Optional) dissolve borders into a single polygon
ng <- new_guinea %>%
  st_union()



# plot points
plantCollPlot <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = plantSEAsiaCollSF, col = "yellow", pch = 20, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)

regionPoly <- ng |> st_make_valid()

regionGrid <- regionPoly |>
  st_make_grid(cellsize = 0.3, what = "polygons") |>
  st_intersection(regionPoly) |>
  st_collection_extract("POLYGON") |>
  st_make_valid() |>
  st_sf() |>
  dplyr::mutate(cellid = dplyr::row_number())

gridPlot <-
  ggplot() +
  geom_sf(data = regionPoly) +
  geom_sf(data = regionGrid) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
gridPlot

plantSEAsiaCollSF <- plantSEAsiaCollSF |> st_make_valid()

plantCollRaster <- regionGrid |>
  st_join(plantSEAsiaCollSF, join = st_intersects) |>
  dplyr::mutate(overlap = ifelse(!is.na(id), 1, 0)) |>
  dplyr::group_by(cellid) |>
  dplyr::summarize(numCollections = sum(overlap), .groups = "drop")

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
bin_levels <- c("0","125","26100","101500","5011000",
                "10011500","15012000",">2000")

# Bin + lock factor levels
plantCollRaster_binned <- plantCollRaster %>%
  mutate(collection_bin = cut(
    numCollections,
    breaks = c(-Inf, 0, 25, 100, 500, 1000, 1500, 2000, Inf),
    labels = bin_levels,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = bin_levels))

# Color palette named by the same levels (note the orange for "15012000")
#pal <- c(
  #"0"          = "#FFFFFF",
  #"125"       = "#EAF2FF",
  #"26100"     = "#D7E9FF",
  #"101500"    = "#C3DEFF",
  #"5011000"   = "#AECFFF",
  #"10011500"  = "#FFF6BF",
  #"15012000"  = "#FFE1B8", 
  #">2000"      = "#FFB6C8"
#)

pal <- c(
  "0" = "#000000",
  "125"      = "#3D3D00",
  "26100"    = "#666600",
  "101500"   = "#8C8C00",
  "5011000"  = "#B3B300",
  "10011500" = "#D9D900",
  "15012000" = "#FFFF00",
  ">2000"     = "#FFFF66"
)


plantCollRasterPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = plantCollRaster_binned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Occurrences",
    values = pal,
    limits = bin_levels,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )

ggsave(
  filename = "plantSampleLocationsRasterMap.png",  # file name and extension
  plot     = plantCollRasterPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

# Digitised occurrence density per region

counts <- as.data.frame(table(plantSEAsiaOccData[[13]]))
names(counts) <- c("Region", "Observations")

# I don't know accurate these surface areas are and to what specific borders they exactly apply

areas <- data.frame(
  Region = c("Bali","Brunei","Indonesian Borneo","Indonesian Papua",
             "Java","Lesser Sunda Islands","Malaysian Borneo","Maluku",
             "Papua New Guinea","Phillipines","Sulawesi","Sumatra"),
  Area_km2 = c(5590.15,5765,534698.27,412214.61,132598.77,67128.38 + 14950,
               198445.64,78897,462840,300000,174416.16,482286.55)
)

density_table <- counts %>%
  left_join(areas, by = "Region") %>%
  mutate(Density = Observations / Area_km2)


```
# Fig. 2 Heatmaps of Alpha Diversity 

# Frogs

```{r}

frogSEAsiaCollSF <- st_as_sf(frogSEAsiaCollXY, coords = c("long", "lat"), crs = 4326)
# no group_by / summarize here

frogsAlpha <- regionGrid |>
  st_join(frogSEAsiaCollSF, join = st_intersects, left = TRUE) |>
  group_by(cellid) |>
  summarise(
    alpha = n_distinct(sp, na.rm = TRUE),
    .groups = "drop"
  )

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
frogs_binsAlpha <- c("0","1-10","1120","2130","3140","4150")

# Bin + lock factor levels
frogsAlphaBinned <- frogsAlpha %>%
  mutate(collection_bin = cut(
    alpha,
    breaks = c(-Inf, 0, 10, 20, 30, 40, 50),
    labels = frogs_binsAlpha,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = frogs_binsAlpha))


frogs_palAlpha <- c(
  "0" = "#000000",
  "110"      = "#3D3D00",
  "1120"    = "#666600",
  "2130"   = "#8C8C00",
  "3140"  = "#B3B300",
  "4150" = "#D9D900"
  )


frogsAlphaPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = frogsAlphaBinned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Species richness",
    values = frogs_palAlpha,
    limits = frogs_binsAlpha,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = frogs_palAlpha))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )

ggsave(
  filename = "frogAlphaMap.png",  # file name and extension
  plot     = frogsAlphaPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

```

# Mammals

```{r}

mammalSEAsiaCollSF <- st_as_sf(mammalSEAsiaCollXY, coords = c("long", "lat"), crs = 4326)
# no group_by / summarize here

mammalAlpha <- regionGrid |>
  st_join(mammalSEAsiaCollSF, join = st_intersects, left = TRUE) |>
  group_by(cellid) |>
  summarise(
    alpha = n_distinct(sp, na.rm = TRUE),
    .groups = "drop"
  )

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
binsAlpha <- c("0","1-10","1120","2130","3140","4150",
                "5160",">60")

# Bin + lock factor levels
mammalAlphaBinned <- mammalAlpha %>%
  mutate(collection_bin = cut(
    alpha,
    breaks = c(-Inf, 0, 10, 20, 30, 40, 50, 60, Inf),
    labels = binsAlpha,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = binsAlpha))


palAlpha <- c(
  "0" = "#000000",
  "110"      = "#3D3D00",
  "1120"    = "#666600",
  "2130"   = "#8C8C00",
  "3140"  = "#B3B300",
  "4150" = "#D9D900",
  "5160" = "#FFFF00",
  ">60"     = "#FFFF66"
)

mammalAlphaPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = mammalAlphaBinned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Species richness",
    values = palAlpha,
    limits = binsAlpha,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )
mammalAlphaPlot

ggsave(
  filename = "mammalAlphaMap.png",  # file name and extension
  plot     = mammalAlphaPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

```

# Birds

```{r}

birdSEAsiaCollSF <- st_as_sf(birdSEAsiaCollXY, coords = c("long", "lat"), crs = 4326)
# no group_by / summarize here

birdAlpha <- regionGrid |>
  st_join(birdSEAsiaCollSF, join = st_intersects, left = TRUE) |>
  group_by(cellid) |>
  summarise(
    alpha = n_distinct(sp, na.rm = TRUE),
    .groups = "drop"
  )

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
binsAlpha <- c("0","1-10","1120","2130","3140","4150",
                "5160",">60")

# Bin + lock factor levels
birdAlphaBinned <- birdAlpha %>%
  mutate(collection_bin = cut(
    alpha,
    breaks = c(-Inf, 0, 10, 20, 30, 40, 50, 60, Inf),
    labels = binsAlpha,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = binsAlpha))


palAlpha <- c(
  "0" = "#000000",
  "110"      = "#3D3D00",
  "1120"    = "#666600",
  "2130"   = "#8C8C00",
  "3140"  = "#B3B300",
  "4150" = "#D9D900",
  "5160" = "#FFFF00",
  ">60"     = "#FFFF66"
)

birdAlphaPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = birdAlphaBinned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Species richness",
    values = palAlpha,
    limits = binsAlpha,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )
birdAlphaPlot

ggsave(
  filename = "birdAlphaMap.png",  # file name and extension
  plot     = birdAlphaPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

```

# Squamates

```{r}

squamateSEAsiaCollSF <- st_as_sf(squamateSEAsiaCollXY, coords = c("long", "lat"), crs = 4326)
# no group_by / summarize here

squamateAlpha <- regionGrid |>
  st_join(squamateSEAsiaCollSF, join = st_intersects, left = TRUE) |>
  group_by(cellid) |>
  summarise(
    alpha = n_distinct(sp, na.rm = TRUE),
    .groups = "drop"
  )

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
binsAlpha <- c("0","1-10","1120","2130","3140","4150",
                "5160",">60")

# Bin + lock factor levels
squamateAlphaBinned <- squamateAlpha %>%
  mutate(collection_bin = cut(
    alpha,
    breaks = c(-Inf, 0, 10, 20, 30, 40, 50, 60, Inf),
    labels = binsAlpha,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = binsAlpha))


palAlpha <- c(
  "0" = "#000000",
  "110"      = "#3D3D00",
  "1120"    = "#666600",
  "2130"   = "#8C8C00",
  "3140"  = "#B3B300",
  "4150" = "#D9D900",
  "5160" = "#FFFF00",
  ">60"     = "#FFFF66"
)

squamateAlphaPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = squamateAlphaBinned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Species richness",
    values = palAlpha,
    limits = binsAlpha,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )
squamateAlphaPlot

ggsave(
  filename = "squamateAlphaMap.png",  # file name and extension
  plot     = squamateAlphaPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

```

# Vascular plants

```{r}

plantSEAsiaCollSF <- st_as_sf(plantSEAsiaCollXY, coords = c("long", "lat"), crs = 4326)
# no group_by / summarize here

plantAlpha <- regionGrid |>
  st_join(plantSEAsiaCollSF, join = st_intersects, left = TRUE) |>
  group_by(cellid) |>
  summarise(
    alpha = n_distinct(sp, na.rm = TRUE),
    .groups = "drop"
  )

# Define levels once and reuse everywhere (avoids dash/typo mismatches)
binsAlpha <- c("0","1-10","1120","2130","3140","4150",
                "5160",">60")

# Bin + lock factor levels
plantAlphaBinned <- plantAlpha %>%
  mutate(collection_bin = cut(
    alpha,
    breaks = c(-Inf, 0, 10, 20, 30, 40, 50, 60, Inf),
    labels = binsAlpha,
    include.lowest = TRUE, right = TRUE
  )) %>%
  mutate(collection_bin = factor(collection_bin, levels = binsAlpha))


palAlpha <- c(
  "0" = "#000000",
  "110"      = "#3D3D00",
  "1120"    = "#666600",
  "2130"   = "#8C8C00",
  "3140"  = "#B3B300",
  "4150" = "#D9D900",
  "5160" = "#FFFF00",
  ">60"     = "#FFFF66"
)

plantAlphaPlot <-
  ggplot() +
  # ocean colour: panel background
  #theme(panel.background = element_rect(fill = "grey95", colour = NA),
        #plot.background  = element_rect(fill = "grey95", colour = NA)) +
  # land polygons from regionPoly
geom_sf(data = plantAlphaBinned, aes(fill = collection_bin), color = NA) +
    scale_fill_manual(
    name   = "Species richness",
    values = palAlpha,
    limits = binsAlpha,   # force order & inclusion
    drop   = FALSE,
    guide_legend(override.aes = list(fill = pal))
  ) +
    geom_sf(data = regionPoly, fill = NA, colour = "grey60", linewidth = 0.2) +
  #geom_sf(data = borders_clip, color = "grey60", linewidth = 0.2) +
  coord_sf() +
  theme(
    legend.position        = "inside",           # <- tell ggplot to use inside placement
    legend.position.inside = c(0.25, 0.45),    # <- near the top-right (Pacific corner)
    legend.justification   = c(1, 1),            # align legend's top-right to that point
    legend.background      = element_rect(fill = NA, colour = NA),
    legend.title = element_text(size = 8, face='bold'),
    legend.margin          = margin(4, 4, 4, 4),
    legend.key.width       = unit(0.3, "cm"),
    legend.key.height      = unit(0.3, "cm")
  )
plantAlphaPlot

ggsave(
  filename = "plantAlphaMap.png",  # file name and extension
  plot     = plantAlphaPlot,       # your ggplot object
  width    = 8,                          # width in inches (adjust as needed)
  height   = 6,                          # height in inches (adjust as needed)
  units    = "in",                        # units for width/height
  dpi      = 300                          # resolution; affects rasterized elements
)

```


# Fig 3: Bivariate choropleth rasters

# Frogs

```{r}

fr_bi_grid <- frogsCollRaster_binned %>%
  mutate(alpha = frogsAlphaBinned[[2]], .before = 3) %>%
  select(-5)

fr_bi_grid <- fr_bi_grid %>%
  mutate(
    # --- collections classes ---
    numCollectionsLab = case_when(
      numCollections == 0                      ~ 0L,
      numCollections >= 1   & numCollections <= 100 ~ 1L,
      numCollections >= 101 & numCollections <= 200 ~ 2L,
      numCollections > 200                      ~ 3L,
      TRUE ~ NA_integer_
    ),

    # --- richness (alpha) classes ---
    alphaLab = case_when(
      alpha == 0                     ~ 0L,
      alpha >= 1  & alpha <= 20      ~ 1L,
      alpha >= 21 & alpha <= 40      ~ 2L,
      alpha > 40                     ~ 3L,
      TRUE ~ NA_integer_
    ),

    # --- bivariate code ---
    jointLab = case_when(
      is.na(numCollectionsLab) | is.na(alphaLab) ~ NA_character_,
      TRUE ~ paste0(numCollectionsLab, "-", alphaLab)
    )
  )

fr_bi_grid <- fr_bi_grid %>%
  mutate(
    jointLab_plot = if_else(jointLab == "0-0", NA_character_, jointLab)
  )

bi_pal_3x3 <- c(
  "1-1" = "#7A7A7A", "1-2" = "#B59B3A", "1-3" = "#FFD200",
  "2-1" = "#B0B0B0", "2-2" = "#D8C98A", "2-3" = "#FFE680",
  "3-1" = "#E6E6E6", "3-2" = "#F2EBCB", "3-3" = "#FFF4B3"
)

p <- ggplot() +
  # bivariate grid
  geom_sf(data = fr_bi_grid, aes(fill = jointLab), color = NA) +
  # outline on top
  geom_sf(data = regionPoly, fill = NA, linewidth = 0.3) +
  scale_fill_manual(values = bi_pal_3x3, na.value = "black") +
  coord_sf(datum = NA) +
  theme_void() +
  theme(
    legend.position = "none"
  )

```

# Fig 4: Bivariate choropleth heatmaps

# Frogs

```{r}

fr_bi_grid <- frogsCollRaster_binned %>%
  mutate(alpha = frogsAlphaBinned[[2]], .before = 3) %>%
  select(-5)

# maxima
max_collections <- max(fr_bi_grid$numCollections, na.rm = TRUE)
max_alpha       <- max(fr_bi_grid$alpha, na.rm = TRUE)


fr_cont <- fr_bi_grid %>%
  mutate(
    # scale to [0,1] by max (guard against max == 0)
    coll01  = numCollections / max_collections,
    alpha01 = alpha / max_alpha,

    # clamp
    coll01  = pmin(pmax(coll01, 0), 1),
    alpha01 = pmin(pmax(alpha01, 0), 1),

    # RGB mapping: R = richness, B = collections, G = 0
    fill = grDevices::rgb(alpha01, 0, coll01)
  )

p <- ggplot() +
  geom_sf(data = fr_cont, aes(fill = fill), color = NA) +
  geom_sf(data = regionPoly, fill = NA, linewidth = 0.3) +
  scale_fill_identity(na.value = "black") +
  coord_sf() 

# ---- Continuous 2D legend (exact same rule) ----
legend_dim <- 250

leg_df <- expand_grid(
  coll01  = seq(0, 1, length.out = legend_dim),   # x-axis: collections
  alpha01 = seq(0, 1, length.out = legend_dim)    # y-axis: richness
) %>%
  mutate(
    fill    = grDevices::rgb(alpha01, 0, coll01)
  )

legend_plot <- ggplot(leg_df, aes(x = coll01, y = alpha01, fill = fill)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_identity() +
  coord_equal(expand = FALSE) +
  theme_void() +
  theme(
    plot.margin = margin(2, 2, 2, 2)
  )

final_plot <- ggdraw() +
  draw_plot(p, 0, 0, 1, 1) +
  draw_plot(
    legend_plot,
    x = 0.15,   # distance from left (01)
    y = 0.35,   # distance from bottom (01)
    width  = 0.1,
    height = 0.1
  )

```

# Mammals

```{r}

mammals_bi_grid <- mammalCollRaster_binned %>%
  mutate(alpha = mammalAlphaBinned[[2]], .before = 3) %>%
  select(-5)

# maxima
max_collections <- max(mammals_bi_grid$numCollections, na.rm = TRUE)
max_alpha       <- max(mammals_bi_grid$alpha, na.rm = TRUE)


mammals_cont <- mammals_bi_grid %>%
  mutate(
    # scale to [0,1] by max (guard against max == 0)
    coll01  = numCollections / max_collections,
    alpha01 = alpha / max_alpha,

    # clamp
    coll01  = pmin(pmax(coll01, 0), 1),
    alpha01 = pmin(pmax(alpha01, 0), 1),

    # RGB mapping: R = richness, B = collections, G = 0
    fill = grDevices::rgb(alpha01, 0, coll01)
  )

p <- ggplot() +
  geom_sf(data = mammals_cont, aes(fill = fill), color = NA) +
  geom_sf(data = regionPoly, fill = NA, linewidth = 0.3) +
  scale_fill_identity(na.value = "black") +
  coord_sf() 

# ---- Continuous 2D legend (exact same rule) ----
legend_dim <- 250

leg_df <- expand_grid(
  coll01  = seq(0, 1, length.out = legend_dim),   # x-axis: collections
  alpha01 = seq(0, 1, length.out = legend_dim)    # y-axis: richness
) %>%
  mutate(
    fill    = grDevices::rgb(alpha01, 0, coll01)
  )

legend_plot <- ggplot(leg_df, aes(x = coll01, y = alpha01, fill = fill)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_identity() +
  coord_equal(expand = FALSE) +
  theme_void() +
  theme(
    plot.margin = margin(2, 2, 2, 2)
  )

final_plot <- ggdraw() +
  draw_plot(p, 0, 0, 1, 1) +
  draw_plot(
    legend_plot,
    x = 0.15,   # distance from left (01)
    y = 0.35,   # distance from bottom (01)
    width  = 0.1,
    height = 0.1
  )

```

# Birds

```{r}

birds_bi_grid <- birdCollRaster_binned %>%
  mutate(alpha = birdAlphaBinned[[2]], .before = 3) %>%
  select(-5)

# maxima
max_collections <- max(birds_bi_grid$numCollections, na.rm = TRUE)
max_alpha       <- max(birds_bi_grid$alpha, na.rm = TRUE)


birds_cont <- birds_bi_grid %>%
  mutate(
    # scale to [0,1] by max (guard against max == 0)
    coll01  = numCollections / max_collections,
    alpha01 = alpha / max_alpha,

    # clamp
    coll01  = pmin(pmax(coll01, 0), 1),
    alpha01 = pmin(pmax(alpha01, 0), 1),

    # RGB mapping: R = richness, B = collections, G = 0
    fill = grDevices::rgb(alpha01, 0, coll01)
  )

p <- ggplot() +
  geom_sf(data = birds_cont, aes(fill = fill), color = NA) +
  geom_sf(data = regionPoly, fill = NA, linewidth = 0.3) +
  scale_fill_identity(na.value = "black") +
  coord_sf() 

# ---- Continuous 2D legend (exact same rule) ----
legend_dim <- 250

leg_df <- expand_grid(
  coll01  = seq(0, 1, length.out = legend_dim),   # x-axis: collections
  alpha01 = seq(0, 1, length.out = legend_dim)    # y-axis: richness
) %>%
  mutate(
    fill    = grDevices::rgb(alpha01, 0, coll01)
  )

legend_plot <- ggplot(leg_df, aes(x = coll01, y = alpha01, fill = fill)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_identity() +
  coord_equal(expand = FALSE) +
  theme_void() +
  theme(
    plot.margin = margin(2, 2, 2, 2)
  )

final_plot <- ggdraw() +
  draw_plot(p, 0, 0, 1, 1) +
  draw_plot(
    legend_plot,
    x = 0.15,   # distance from left (01)
    y = 0.35,   # distance from bottom (01)
    width  = 0.1,
    height = 0.1
  )

```

# Squamates

```{r}

squamates_bi_grid <- squamateCollRaster_binned %>%
  mutate(alpha = squamateAlphaBinned[[2]], .before = 3) %>%
  select(-5)

# maxima
max_collections <- max(squamates_bi_grid$numCollections, na.rm = TRUE)
max_alpha       <- max(squamates_bi_grid$alpha, na.rm = TRUE)


squamates_cont <- squamates_bi_grid %>%
  mutate(
    # scale to [0,1] by max (guard against max == 0)
    coll01  = numCollections / max_collections,
    alpha01 = alpha / max_alpha,

    # clamp
    coll01  = pmin(pmax(coll01, 0), 1),
    alpha01 = pmin(pmax(alpha01, 0), 1),

    # RGB mapping: R = richness, B = collections, G = 0
    fill = grDevices::rgb(alpha01, 0, coll01)
  )

p <- ggplot() +
  geom_sf(data = squamates_cont, aes(fill = fill), color = NA) +
  geom_sf(data = regionPoly, fill = NA, linewidth = 0.3) +
  scale_fill_identity(na.value = "black") +
  coord_sf() 

# ---- Continuous 2D legend (exact same rule) ----
legend_dim <- 250

leg_df <- expand_grid(
  coll01  = seq(0, 1, length.out = legend_dim),   # x-axis: collections
  alpha01 = seq(0, 1, length.out = legend_dim)    # y-axis: richness
) %>%
  mutate(
    fill    = grDevices::rgb(alpha01, 0, coll01)
  )

legend_plot <- ggplot(leg_df, aes(x = coll01, y = alpha01, fill = fill)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_identity() +
  coord_equal(expand = FALSE) +
  theme_void() +
  theme(
    plot.margin = margin(2, 2, 2, 2)
  )

final_plot <- ggdraw() +
  draw_plot(p, 0, 0, 1, 1) +
  draw_plot(
    legend_plot,
    x = 0.15,   # distance from left (01)
    y = 0.35,   # distance from bottom (01)
    width  = 0.1,
    height = 0.1
  )

```

# Vascular plants

```{r}

plants_bi_grid <- plantCollRaster_binned %>%
  mutate(alpha = plantAlphaBinned[[2]], .before = 3) %>%
  select(-5)

# maxima
max_collections <- max(plants_bi_grid$numCollections, na.rm = TRUE)
max_alpha       <- max(plants_bi_grid$alpha, na.rm = TRUE)


plants_cont <- plants_bi_grid %>%
  mutate(
    # scale to [0,1] by max (guard against max == 0)
    coll01  = numCollections / max_collections,
    alpha01 = alpha / max_alpha,

    # clamp
    coll01  = pmin(pmax(coll01, 0), 1),
    alpha01 = pmin(pmax(alpha01, 0), 1),

    # RGB mapping: R = richness, B = collections, G = 0
    fill = grDevices::rgb(alpha01, 0, coll01)
  )

p <- ggplot() +
  geom_sf(data = plants_cont, aes(fill = fill), color = NA) +
  geom_sf(data = regionPoly, fill = NA, linewidth = 0.3) +
  scale_fill_identity(na.value = "black") +
  coord_sf() 

# ---- Continuous 2D legend (exact same rule) ----
legend_dim <- 250

leg_df <- expand_grid(
  coll01  = seq(0, 1, length.out = legend_dim),   # x-axis: collections
  alpha01 = seq(0, 1, length.out = legend_dim)    # y-axis: richness
) %>%
  mutate(
    fill    = grDevices::rgb(alpha01, 0, coll01)
  )

legend_plot <- ggplot(leg_df, aes(x = coll01, y = alpha01, fill = fill)) +
  geom_raster(interpolate = TRUE) +
  scale_fill_identity() +
  coord_equal(expand = FALSE) +
  theme_void() +
  theme(
    plot.margin = margin(2, 2, 2, 2)
  )

final_plot <- ggdraw() +
  draw_plot(p, 0, 0, 1, 1) +
  draw_plot(
    legend_plot,
    x = 0.15,   # distance from left (01)
    y = 0.35,   # distance from bottom (01)
    width  = 0.1,
    height = 0.1
  )

```

# Fig 5: Protected areas of New Guinea

```{r}

## Create Region mask

# Countries (Papua New Guinea only)
countries <- ne_countries(scale = "large", returnclass = "sf")

png <- countries %>%
  filter(name == "Papua New Guinea")

# Indonesian provinces
states <- ne_states(country = "Indonesia",
                    returnclass = "sf")

papua_id <- states %>%
  filter(name %in% c("Papua", "Papua Barat"))

png2 <- png %>%
  transmute(
    unit = name,          # "Papua New Guinea"
    geom = geometry
  ) %>%
  st_as_sf()

papua2 <- papua_id %>%
  transmute(
    unit = name,          # "Papua", "Papua Barat"
    geom = geometry
  ) %>%
  st_as_sf()

new_guinea <- bind_rows(
  st_make_valid(png2),
  st_make_valid(papua2)
)


# (Optional) dissolve borders into a single polygon
ng <- new_guinea %>%
  st_union()


regionPoly <- ng |> st_make_valid()

## Import shapefiles

pa_dir <- "/protected_areas"  

pa_files <- c(
  "shp0_polygons_png.shp",
  "shp1_polygons_png.shp",
  "shp2_polygons_png.shp",
  "shp0_polygons_indonesia.shp",
  "shp1_polygons_indonesia.shp",
  "shp2_polygons_indonesia.shp"
)

pa_paths <- file.path(getwd(),pa_dir, pa_files)

pa_list <- map(pa_paths, ~ st_read(.x, quiet = TRUE))

# pick a target CRS (use your region polygon CRS, or force WGS84)
target_crs <- st_crs(regionPoly)  # or st_crs(4326)

pa_merged <- pa_list %>%
  map(~ st_make_valid(.x)) %>%
  map(~ st_transform(.x, target_crs)) %>%
  reduce(bind_rows)

pa_ng <- pa_merged %>%
  st_make_valid() %>%
  st_filter(regionPoly) %>%          # keeps only features that touch regionPoly
  st_intersection(regionPoly)        # actually clips to the boundary

ggplot() +
  geom_sf(data = regionPoly, fill = "black", color = "black", linewidth = 0.4) +
  geom_sf(data = pa_ng, fill = "NA", color = "white", alpha = 0.6) +
  coord_sf(expand = FALSE) +
  theme_minimal() #+
  #labs(
    #title = "Protected areas on New Guinea",
    #subtitle = "Papua New Guinea + Indonesian provinces (Papua, Papua Barat)",
    #fill = "Protected areas"
  #)


```

# Fig S1: Raw cleaned occurrence data
```{r}

## FROGS

frogPointMap <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = frogSEAsiaCollSF, col = "yellow", alpha = 0.2 , pch = 16, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
frogPointMap
  
  ggsave(
    filename = paste0("frog", "_pointmap", ".png"),
    plot     = frogPointMap,
    width    = 8,
    height   = 6,
    units    = "in",
    dpi      = 300
  )
  
## MAMMALS
  
  mammalPointMap <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = mammalSEAsiaCollSF, col = "yellow", alpha = 0.2 , pch = 16, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
  
  ggsave(
    filename = paste0("mammal", "_pointmap", ".png"),
    plot     = mammalPointMap,
    width    = 8,
    height   = 6,
    units    = "in",
    dpi      = 300
  )

## BIRDS
  
  birdPointMap <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = birdSEAsiaCollSF, col = "yellow", alpha = 0.2 , pch = 16, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
  
  ggsave(
    filename = paste0("bird", "_pointmap", ".png"),
    plot     = birdPointMap,
    width    = 8,
    height   = 6,
    units    = "in",
    dpi      = 300
  )

## SQUAMATES

squamatePointMap <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = squamateSEAsiaCollSF, col = "yellow", alpha = 0.2 , pch = 16, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
  
  ggsave(
    filename = paste0("squamate", "_pointmap", ".png"),
    plot     = squamatePointMap,
    width    = 8,
    height   = 6,
    units    = "in",
    dpi      = 300
  )

## VASCULAR PLANTS
  
plantPointMap <-
  ggplot() +
  geom_sf(data = ng, fill = "black", linewidth = 0.2) +
  geom_sf(data = plantSEAsiaCollSF, col = "yellow", alpha = 0.2 , pch = 16, cex = 0.8) #+
  #scale_x_continuous(breaks = c(-84)) +
  #theme(
    #plot.background = element_rect(fill = "#f1f2f3"),
    #panel.background = element_rect(fill = "#2F4051"),
    #panel.grid = element_blank(),
    #line = element_blank(),
    #rect = element_blank()
  #)
  
  ggsave(
    filename = paste0("plant", "_pointmap", ".png"),
    plot     = plantPointMap,
    width    = 8,
    height   = 6,
    units    = "in",
    dpi      = 300
  )

  
```



## STATS

# Test for spatial randomness
# Birds
```{r}

# Study area
mask_sf <- st_read("PNGIDP.shp")

# Extract coordinates of bird occurrence data
pts_sf <- st_as_sf(
  birdSEAsiaOccData,
  coords = c("long", "lat"),
  crs = 4326,
  remove = FALSE
)

# Define centroids of study area and coordinate data
mask_centroid <- st_coordinates(st_centroid(st_union(mask_sf)))[1, ]
lon0 <- mask_centroid[1]; lat0 <- mask_centroid[2]

# Define CRS for projection
utm_zone <- floor((lon0 + 180) / 6) + 1
epsg_utm <- if (lat0 >= 0) 32600 + utm_zone else 32700 + utm_zone

# Transform data to new CRS
mask_utm <- st_transform(mask_sf, epsg_utm)
pts_utm  <- st_transform(pts_sf, epsg_utm)
# Union in case of multiple polygons
mask_union <- st_union(mask_utm)

# Convert to spatstat window
W <- as.owin(mask_union)

xy <- st_coordinates(pts_utm)

pp <- ppp(
  x = xy[,1],
  y = xy[,2],
  window = W
)

summary(pp)
plot(W)
points(pp, pch = 20, col = "red")

# Perform Quadrat Test with MonteCarlo simulation to test for randomness

qt_mc <- quadrat.test(
  pp,
  nx = 10,
  ny = 10,
  method = "MonteCarlo",
  nsim = 999
)
qt_mc

```

# Squamates

```{r}

# Study area
mask_sf <- st_read("PNGIDP.shp")

# Extract coordinates of bird occurrence data
pts_sf <- st_as_sf(
  squamateSEAsiaOccData,
  coords = c("long", "lat"),
  crs = 4326,
  remove = FALSE
)

# Define centroids of study area and coordinate data
mask_centroid <- st_coordinates(st_centroid(st_union(mask_sf)))[1, ]
lon0 <- mask_centroid[1]; lat0 <- mask_centroid[2]

# Define CRS for projection
utm_zone <- floor((lon0 + 180) / 6) + 1
epsg_utm <- if (lat0 >= 0) 32600 + utm_zone else 32700 + utm_zone

# Transform data to new CRS
mask_utm <- st_transform(mask_sf, epsg_utm)
pts_utm  <- st_transform(pts_sf, epsg_utm)
# Union in case of multiple polygons
mask_union <- st_union(mask_utm)

# Convert to spatstat window
W <- as.owin(mask_union)

xy <- st_coordinates(pts_utm)

pp <- ppp(
  x = xy[,1],
  y = xy[,2],
  window = W
)

summary(pp)
plot(W)
points(pp, pch = 20, col = "red")

# Perform Quadrat Test with MonteCarlo simulation to test for randomness

qt_mc <- quadrat.test(
  pp,
  nx = 10,
  ny = 10,
  method = "MonteCarlo",
  nsim = 999
)
qt_mc

```

# Vascular plants

```{r}

# Study area
mask_sf <- st_read("PNGIDP.shp")

# Extract coordinates of bird occurrence data
pts_sf <- st_as_sf(
  plantSEAsiaOccData,
  coords = c("long", "lat"),
  crs = 4326,
  remove = FALSE
)

# Define centroids of study area and coordinate data
mask_centroid <- st_coordinates(st_centroid(st_union(mask_sf)))[1, ]
lon0 <- mask_centroid[1]; lat0 <- mask_centroid[2]

# Define CRS for projection
utm_zone <- floor((lon0 + 180) / 6) + 1
epsg_utm <- if (lat0 >= 0) 32600 + utm_zone else 32700 + utm_zone

# Transform data to new CRS
mask_utm <- st_transform(mask_sf, epsg_utm)
pts_utm  <- st_transform(pts_sf, epsg_utm)
# Union in case of multiple polygons
mask_union <- st_union(mask_utm)

# Convert to spatstat window
W <- as.owin(mask_union)

xy <- st_coordinates(pts_utm)

pp <- ppp(
  x = xy[,1],
  y = xy[,2],
  window = W
)

summary(pp)
plot(W)
points(pp, pch = 20, col = "red")

# Perform Quadrat Test with MonteCarlo simulation to test for randomness

qt_mc <- quadrat.test(
  pp,
  nx = 10,
  ny = 10,
  method = "MonteCarlo",
  nsim = 999
)
qt_mc


```

